source: https://gist.github.com/tony-sol/039152cd18fbe25c5b3364d9c51f7161

---
tag:
  - algos
  - computer-science
---

# Алгоритмы и структуры данных

- [[#Общая часть|Общая часть]]
- [[#1. Сложность алгоритмов|1. Сложность алгоритмов]]
	- [[#1. Сложность алгоритмов#1.1. Классы сложности|1.1. Классы сложности]]
- [[#2. Структуры данных|2. Структуры данных]]
	- [[#2. Структуры данных#2.1. Определение структуры данных|2.1. Определение структуры данных]]
	- [[#2. Структуры данных#2.2. Основные типы структур данных|2.2. Основные типы структур данных]]
		- [[#2.2. Основные типы структур данных#2.2.1. Массив (Array)|2.2.1. Массив (Array)]]
		- [[#2.2. Основные типы структур данных#2.2.2. Связанный список (Linked List)|2.2.2. Связанный список (Linked List)]]
		- [[#2.2. Основные типы структур данных#2.2.3. Стек (Stack)|2.2.3. Стек (Stack)]]
		- [[#2.2. Основные типы структур данных#2.2.4. Очередь (Queue)|2.2.4. Очередь (Queue)]]
		- [[#2.2. Основные типы структур данных#2.2.5. Дерево (Tree)|2.2.5. Дерево (Tree)]]
		- [[#2.2. Основные типы структур данных#2.2.6. Граф (Graph)|2.2.6. Граф (Graph)]]
	- [[#2. Структуры данных#2.3. Решение задач с использованием структур данных|2.3. Решение задач с использованием структур данных]]
- [[#3. Алгоритмы сортировки|3. Алгоритмы сортировки]]
	- [[#3. Алгоритмы сортировки#3.1. Общие понятия|3.1. Общие понятия]]
	- [[#3. Алгоритмы сортировки#3.2. Перечень алгоритмов сортировки|3.2. Перечень алгоритмов сортировки]]
		- [[#3.2. Перечень алгоритмов сортировки#3.2.1. Сортировка пузырьком (Bubble Sort)|3.2.1. Сортировка пузырьком (Bubble Sort)]]
		- [[#3.2. Перечень алгоритмов сортировки#3.2.2. Сортировка выбором (Selection Sort)|3.2.2. Сортировка выбором (Selection Sort)]]
		- [[#3.2. Перечень алгоритмов сортировки#3.2.3. Сортировка вставками (Insertion Sort)|3.2.3. Сортировка вставками (Insertion Sort)]]
		- [[#3.2. Перечень алгоритмов сортировки#3.2.4. Быстрая сортировка (Quick Sort)|3.2.4. Быстрая сортировка (Quick Sort)]]
		- [[#3.2. Перечень алгоритмов сортировки#3.2.5. Сортировка слиянием (Merge Sort)|3.2.5. Сортировка слиянием (Merge Sort)]]
		- [[#3.2. Перечень алгоритмов сортировки#3.2.6. Сортировка кучей (Heap Sort)|3.2.6. Сортировка кучей (Heap Sort)]]
- [[#4. Алгоритмы поиска|4. Алгоритмы поиска]]
	- [[#4. Алгоритмы поиска#4.1. Общие понятия|4.1. Общие понятия]]
	- [[#4. Алгоритмы поиска#4.2. Перечень алгоритмов поиска|4.2. Перечень алгоритмов поиска]]
		- [[#4.2. Перечень алгоритмов поиска#4.2.1. Линейный поиск (Linear Search)|4.2.1. Линейный поиск (Linear Search)]]
		- [[#4.2. Перечень алгоритмов поиска#4.2.2. Поиск по хэш-таблице (Hash Search)|4.2.2. Поиск по хэш-таблице (Hash Search)]]
		- [[#4.2. Перечень алгоритмов поиска#4.2.3. Бинарный поиск (Binary Search)|4.2.3. Бинарный поиск (Binary Search)]]
		- [[#4.2. Перечень алгоритмов поиска#4.2.4. Интерполяционный поиск (Interpolation Search)|4.2.4. Интерполяционный поиск (Interpolation Search)]]
		- [[#4.2. Перечень алгоритмов поиска#4.2.5. Двоичное дерево поиска (Binary Search Tree)|4.2.5. Двоичное дерево поиска (Binary Search Tree)]]
	- [[#4. Алгоритмы поиска#4.3.  Алгоритмы на графах|4.3.  Алгоритмы на графах]]
		- [[#4.3.  Алгоритмы на графах#4.3.1. Обход графа|4.3.1. Обход графа]]
		- [[#4.3.  Алгоритмы на графах#4.3.2. Поиск кратчайшего пути|4.3.2. Поиск кратчайшего пути]]
		- [[#4.3.  Алгоритмы на графах#4.3.3. Топологическая сортировка|4.3.3. Топологическая сортировка]]
		- [[#4.3.  Алгоритмы на графах#4.3.4. Минимальное остовное дерево|4.3.4. Минимальное остовное дерево]]
- [[#5. Алгоритмы генетического поиска|5. Алгоритмы генетического поиска]]
	- [[#5. Алгоритмы генетического поиска#5.1. Применение|5.1. Применение]]
	- [[#5. Алгоритмы генетического поиска#5.2. Примеры|5.2. Примеры]]
		- [[#5.2. Примеры#5.2.1. Пример реализации на PHP|5.2.1. Пример реализации на PHP]]
		- [[#5.2. Примеры#5.2.2. Пример реализации на Python|5.2.2. Пример реализации на Python]]
- [[#6. Динамическое программирование|6. Динамическое программирование]]
- [[#7. Жадные алгоритмы|7. Жадные алгоритмы]]
- [[#8. Рекурсия|8. Рекурсия]]



## Общая часть

Перед собеседованием по алгоритмам важно иметь понимание основных концепций и алгоритмов, используемых в компьютерных науках. Ниже перечислены некоторые из них:

1. Сложность алгоритмов: понимание того, как измерять сложность алгоритма и как она влияет на производительность.

2. Структуры данных: понимание основных типов данных, таких как массивы, связные списки, стеки, очереди и деревья, и умение выбирать подходящую структуру данных для решения задачи.

3. Алгоритмы сортировки: понимание основных алгоритмов сортировки, таких как сортировка пузырьком, сортировка вставками, сортировка выбором, быстрая сортировка и сортировка слиянием.

4. Графы: понимание основных понятий, связанных с графами, таких как вершины, ребра, направленные и ненаправленные графы, а также алгоритмы поиска в глубину и поиска в ширину.

5. Алгоритмы генетического поиска: понимание концепции алгоритмов генетического поиска и умение применять их для решения задач оптимизации.

6. Динамическое программирование: понимание концепции динамического программирования и умение применять его для решения сложных задач.

7. Жадные алгоритмы: понимание концепции жадных алгоритмов и умение применять их для решения оптимизационных задач.

8. Рекурсия: понимание концепции рекурсии и умение применять ее для решения задач.

9. Бинарный поиск: понимание концепции бинарного поиска и умение применять его для решения задач.

Важно также практиковать решение задач и уметь объяснять свои мыслительные процессы при решении задач. Поэтому рекомендуется решать множество задач, связанных с каждым из перечисленных выше концептов, и тренироваться в объяснении своих решений.

## 1. Сложность алгоритмов

### 1.1. Классы сложности

Сложность алгоритмов позволяет оценить, как меняется время выполнения алгоритма и объем используемой памяти при увеличении размера входных данных. Обычно сложность алгоритма измеряется в терминах временной сложности (time complexity) и пространственной сложности (space complexity). 

Временная сложность указывает на количество операций, которые выполняет алгоритм в зависимости от размера входных данных. Она позволяет оценить, насколько быстро работает алгоритм. Временная сложность обычно выражается с использованием "О-нотации" (Big O notation) и обозначает асимптотическую верхнюю границу роста функции временной сложности.

Пространственная сложность указывает на объем памяти, который требуется для выполнения алгоритма в зависимости от размера входных данных. Она позволяет оценить, сколько дополнительной памяти потребуется для хранения данных и промежуточных результатов выполнения алгоритма. Пространственная сложность также выражается с использованием "О-нотации" и обозначает асимптотическую верхнюю границу роста функции пространственной сложности.

Вот некоторые распространенные классы сложности алгоритмов, упорядоченные от наименьшей к наибольшей:

- O(1) - постоянная сложность. Время выполнения и объем памяти не зависят от размера входных данных. Пример: доступ к элементу массива по индексу.

- O(log n) - логарифмическая сложность. Время выполнения и объем памяти увеличиваются логарифмически при увеличении размера входных данных. Пример: бинарный поиск.

- O(n) - линейная сложность. Время выполнения и объем памяти линейно зависят от размера входных данных. Пример: проход по массиву.

- O(n log n) - линейно-логарифмическая сложность. Время выполнения и объем памяти увеличиваются пропорционально произведению размера входных данных на логарифм от размера входных данных. Примеры: быстрая сортировка (Quick Sort), сортировка слиянием (Merge Sort).

- O(n^2) - квадратичная сложность. Время выполнения и объем памяти увеличиваются квадратично при увеличении размера входных данных. Пример: сортировка пузырьком (Bubble Sort), сортировка вставками (Insertion Sort).

- O(2^n) - экспоненциальная сложность. Время выполнения и объем памяти увеличиваются экспоненциально при увеличении размера входных данных. Пример: задача о коммивояжере (Travelling Salesman Problem) с полным перебором.

Это только некоторые из распространенных классов сложности алгоритмов. Существуют и другие классы, такие как O(n!), O(n^3), O(2^n), в зависимости от особенностей алгоритма и решаемой задачи. При выборе алгоритма для решения конкретной задачи важно учитывать как его временную, так и пространственную сложность, чтобы найти баланс между эффективностью и требуемыми ресурсами.

## 2. Структуры данных

Перед собеседованием важно иметь хорошее представление о различных структурах данных. Вот несколько ключевых пунктов, которые следует знать:

1. Определение структуры данных: Понимание того, что такое структура данных, ее цель и основные свойства. Структуры данных представляют собой способы организации и хранения данных для обеспечения эффективной манипуляции и доступа к ним.

2. Основные типы структур данных: Некоторые основные типы структур данных включают массивы, списки, стеки, очереди, деревья, хеш-таблицы и графы. Нужно понимать их особенности, операции, которые можно выполнять с ними, и их сложность.

3. Основные операции: Необходимо знать основные операции, которые можно выполнять с каждой структурой данных, такие как вставка, удаление, поиск, обновление и обход.

4. Сложность операций: Знание временной и пространственной сложности операций для каждой структуры данных. Это поможет в оценке эффективности и выборе наиболее подходящей структуры данных для конкретной задачи.

5. Применение структур данных: Понимание сфер применения каждой структуры данных и их особенностей. Например, массивы удобны для доступа к элементам по индексу, списки могут быть использованы для динамического добавления и удаления элементов, а хеш-таблицы обеспечивают быстрый доступ к данным с использованием ключей.

6. Реализация структур данных: Понимание основных принципов реализации структур данных и их алгоритмов. Некоторые структуры данных можно реализовать с использованием массивов, связанных списков или рекурсии.

7. Сравнение структур данных: Умение сравнивать различные структуры данных по производительности, сложности операций, требованиям к памяти и подходящему контексту применения.

8. Решение задач с использованием структур данных: Умение выбрать и применить подходящую структуру данных для решения конкретной задачи, например, поиска, сортировки, фильтрации данных и других операций.

Знание этих основных аспектов структур данных поможет вам быть готовыми к вопросам о структурах данных во время собеседования и позволит вам решать задачи с использованием наиболее эффективных и подходящих структур данных.

### 2.1. Определение структуры данных

Структура данных - это способ организации и хранения данных в компьютерной памяти, который обеспечивает эффективный доступ и манипуляцию с этими данными. Она определяет, как данные будут организованы и какие операции могут быть выполнены над ними.

Основная цель структур данных - это обеспечить эффективное выполнение операций, таких как вставка, удаление, поиск, сортировка и другие. Каждая структура данных имеет свои преимущества и недостатки, и выбор подходящей структуры данных зависит от требуемых операций и характеристик данных.

Структуры данных можно разделить на несколько категорий:

1. Линейные структуры данных: Включают в себя массивы, связанные списки, стеки и очереди. Эти структуры данных организуют данные последовательно, как линейную последовательность элементов.

2. Иерархические структуры данных: Включают в себя деревья и графы. Деревья организуют данные в виде иерархической структуры с корневым элементом и ветвями, а графы позволяют моделировать связи между объектами.

3. Массивы и матрицы: Массивы представляют собой совокупность элементов одного типа, расположенных в непрерывной области памяти. Матрицы являются двумерными массивами и представляют собой таблицу значений, организованных в виде строк и столбцов.

4. Хеш-таблицы: Хеш-таблицы используют хеширование для хранения и быстрого доступа к данным. Они связывают ключи с соответствующими значениями, что позволяет эффективно выполнять операции поиска и вставки.

Кроме того, существуют и другие структуры данных, такие как кучи (heaps), битовые поля (bit arrays), сбалансированные деревья и др.

Понимание основных концепций и целей структур данных поможет вам выбрать подходящую структуру для решения конкретных задач, эффективно манипулировать данными и оптимизировать производительность ваших программ.

Основные операции, которые можно выполнять со структурами данных, включают:

1. Вставка (Insertion): Добавление нового элемента в структуру данных.

2. Удаление (Deletion): Удаление элемента из структуры данных.

3. Поиск (Search): Поиск элемента в структуре данных для определения его наличия или получения его значения.

4. Обновление (Update): Изменение значения существующего элемента в структуре данных.

5. Получение (Access/Get): Получение значения существующего элемента в структуре данных.

6. Сортировка (Sorting): Упорядочивание элементов структуры данных в соответствии с заданным критерием.

7. Обход (Traversal): Посещение каждого элемента структуры данных для выполнения определенных операций, например, вывод на экран или выполнение вычислений.

8. Слияние (Merge): Объединение двух или более структур данных в одну структуру данных.

9. Разделение (Split): Разделение структуры данных на две или более части.

10. Получение размера (Size): Получение количества элементов в структуре данных.

11. Проверка на пустоту (Empty check): Проверка, является ли структура данных пустой.

12. Итерация (Iteration): Последовательный доступ ко всем элементам структуры данных для выполнения определенных операций.

Каждая структура данных может поддерживать различные операции в зависимости от своих характеристик и целей использования. Операции могут быть реализованы по-разному для каждой структуры данных, и их эффективность может различаться в зависимости от выбранной структуры. При выборе структуры данных для конкретной задачи важно учитывать требуемые операции и их ожидаемую производительность.

### 2.2. Основные типы структур данных

Давайте рассмотрим основные типы структур данных подробнее. Учитывайте, что указанные сложности операций являются общими и могут отличаться в зависимости от реализации конкретной структуры данных и ее оптимизаций.

#### 2.2.1. Массив (Array)

Массив представляет собой упорядоченный набор элементов одного типа, расположенных в непрерывной области памяти. Каждый элемент в массиве имеет свой индекс, который позволяет эффективно обращаться к элементам по их позиции. Массивы обладают постоянным временем доступа к элементу по индексу, но ограничены фиксированным размером.

   - Сфера применения: Массивы широко используются в различных областях программирования, включая хранение и доступ к коллекциям элементов.
   - Особенности: Массивы обеспечивают постоянный доступ к элементам по индексу, но требуют заранее определенного размера.

##### 2.2.1.1. Основные операции

- Вставка (Insertion): Добавление элемента в массив по определенному индексу.  O(n) - линейная сложность в худшем случае, когда нужно сдвинуть все элементы вправо.
- Удаление (Deletion): Удаление элемента из массива по определенному индексу. O(n) - линейная сложность в худшем случае, когда нужно сдвинуть все элементы влево.
- Поиск (Search): Поиск элемента в массиве по значению или индексу. O(n) - линейная сложность в худшем случае, когда нужно просмотреть все элементы.
- Обновление (Update): Изменение значения существующего элемента в массиве. O(1) - постоянная сложность, так как доступ осуществляется по индексу.
- Получение (Access/Get): Получение значения элемента массива по индексу. O(1) - постоянная сложность, так как доступ осуществляется по индексу.
- Сортировка (Sorting): Упорядочивание элементов массива в заданном порядке. O(n log n) - средняя сложность для эффективных алгоритмов сортировки, таких как быстрая сортировка или сортировка слиянием.
- Получение размера (Size): Получение количества элементов в массиве. O(1) - постоянная сложность, так как размер массива хранится отдельно.

##### 2.2.1.2. Пример реализации на Python

```python
class Array:
    def __init__(self):
        # Инициализируем пустой массив
        self.data = []

    def add(self, value):
        # Добавляем элемент в конец массива
        self.data.append(value)

    def get(self, index):
        # Возвращаем элемент по индексу
        if 0 <= index < len(self.data):
            return self.data[index]
        else:
            raise IndexError("Index out of bounds")

    def remove(self, index):
        # Удаляем элемент по индексу
        if 0 <= index < len(self.data):
            self.data.pop(index)
        else:
            raise IndexError("Index out of bounds")

    def length(self):
        # Возвращаем длину массива
        return len(self.data)

    def __str__(self):
        # Переопределяем строковое представление объекта
        return str(self.data)

# Пример использования
arr = Array()
arr.add(10)
arr.add(20)
arr.add(30)

print(arr)           # [10, 20, 30]
print(arr.get(1))    # 20
arr.remove(1)
print(arr)           # [10, 30]
print(arr.length())  # 2
```


#### 2.2.2. Связанный список (Linked List)

Связанный список состоит из узлов, где каждый узел содержит данные и ссылку на следующий узел. Это позволяет эффективно добавлять и удалять элементы из списка, поскольку не требуется непрерывное распределение памяти. Однако доступ к элементам осуществляется последовательно, начиная с начала списка, что делает его менее эффективным для произвольного доступа.
   - Сфера применения: Связанные списки эффективно используются при частых операциях вставки и удаления элементов в середине списка.
   - Особенности: Связанные списки позволяют гибко добавлять и удалять элементы, но доступ к элементам выполняется последовательно и требует прохода по списку.
 
##### 2.2.2.1. Основные операции

- Вставка (Insertion): Вставка нового элемента в связанный список в начало, конец или по определенному индексу. O(1) - постоянная сложность, так как требуется только изменение ссылок на узлы.
- Удаление (Deletion): Удаление элемента из связанного списка по значению или индексу. O(1) - постоянная сложность, так как требуется только изменение ссылок на узлы.
- Поиск (Search): Поиск элемента в связанном списке по значению или индексу. O(n) - линейная сложность в худшем случае, так как нужно пройти все узлы для поиска значения.
- Обновление (Update): Изменение значения существующего элемента в связанном списке. O(n) - линейная сложность в худшем случае, так как нужно пройти все узлы для поиска значения.
- Получение (Access/Get): Получение значения элемента связанного списка по индексу. O(n) - линейная сложность в худшем случае, так как нужно пройти все узлы для получения значения.
- Сортировка (Sorting): Упорядочивание элементов связанного списка в заданном порядке. O(n^2) - квадратичная сложность для эффективных алгоритмов сортировки, таких как сортировка вставками.
- Получение размера (Size): Получение количества элементов в связанном списке. O(n) - линейная сложность, так как нужно пройти все узлы для подсчета размера.

##### 2.2.2.2. Пример реализации на Python

```python
class Node:
    def __init__(self, value=None):
        # Узел хранит значение и ссылку на следующий узел
        self.value = value
        self.next = None


class LinkedList:
    def __init__(self):
        # Начало списка (головной узел)
        self.head = None

    def append(self, value):
        # Добавление элемента в конец списка
        new_node = Node(value)
        if self.head is None:
            self.head = new_node
        else:
            current = self.head
            while current.next:
                current = current.next
            current.next = new_node

    def prepend(self, value):
        # Добавление элемента в начало списка
        new_node = Node(value)
        new_node.next = self.head
        self.head = new_node

    def delete(self, value):
        # Удаление элемента с указанным значением
        if self.head is None:
            return
        
        if self.head.value == value:
            self.head = self.head.next
            return
        
        current = self.head
        while current.next and current.next.value != value:
            current = current.next
        
        if current.next is None:
            return
        current.next = current.next.next

    def find(self, value):
        # Поиск элемента по значению
        current = self.head
        while current:
            if current.value == value:
                return True
            current = current.next
        return False

    def display(self):
        # Отображение всех элементов списка
        elements = []
        current = self.head
        while current:
            elements.append(current.value)
            current = current.next
        print(elements)

    def length(self):
        # Вычисление длины списка
        count = 0
        current = self.head
        while current:
            count += 1
            current = current.next
        return count


# Пример использования
ll = LinkedList()
ll.append(10)
ll.append(20)
ll.prepend(5)
ll.display()        # [5, 10, 20]

print(ll.length())  # 3

ll.delete(10)
ll.display()        # [5, 20]

print(ll.find(20))  # True
print(ll.find(10))  # False
```

#### 2.2.3. Стек (Stack)

Стек представляет собой структуру данных, в которой добавление и удаление элементов осуществляется по принципу "последний вошел - первый вышел" (LIFO - Last-In-First-Out). Элементы добавляются и удаляются только с одного конца стека. Основные операции в стеке - это добавление элемента (push) и удаление элемента (pop). Стек может быть реализован как массив или связанный список.

   - Сфера применения: Стеки используются для реализации стековых структур данных и управления вызовами функций в программировании.
   - Особенности: Основной принцип стека - "последний вошел, первый вышел" (LIFO), что означает, что последний добавленный элемент будет первым удаленным.

##### 2.2.3.1. Основные операции со стеком

- Добавление (Push): Добавление элемента в стек. O(1) - постоянная сложность, так как добавление происходит в конец стека.
- Удаление (Pop): Удаление элемента из стека. O(1) - постоянная сложность, так как удаление происходит с конца стека.
- Проверка пустоты (Empty check): Проверка, является ли стек пустым. O(1) - постоянная сложность, так как проверка выполняется за константное время.
- Получение верхнего элемента (Top/Peek): Получение значения верхнего элемента без его удаления.  O(1) - постоянная сложность, так как доступ осуществляется к верхнему элементу.

##### 2.2.3.2. Пример реализации на Python

```python
class Stack:
    def __init__(self):
        # Инициализация пустого стека
        self.stack = []

    def push(self, value):
        # Добавляем элемент в верхушку стека
        self.stack.append(value)

    def pop(self):
        # Удаляем и возвращаем верхний элемент стека
        if not self.is_empty():
            return self.stack.pop()
        else:
            raise IndexError("Pop from empty stack")

    def peek(self):
        # Возвращаем верхний элемент стека без его удаления
        if not self.is_empty():
            return self.stack[-1]
        else:
            raise IndexError("Peek from empty stack")

    def is_empty(self):
        # Проверяем, пуст ли стек
        return len(self.stack) == 0

    def size(self):
        # Возвращаем количество элементов в стеке
        return len(self.stack)

    def __str__(self):
        # Переопределение метода для удобного вывода
        return str(self.stack)


# Пример использования
s = Stack()
s.push(10)
s.push(20)
s.push(30)

print(s)             # [10, 20, 30]
print(s.peek())      # 30

s.pop()
print(s)             # [10, 20]

print(s.size())      # 2
print(s.is_empty())  # False
```

#### 2.2.4. Очередь (Queue)
Очередь представляет собой структуру данных, в которой добавление элементов происходит с одного конца (задняя часть), а удаление - с другого (передняя часть) (FIFO - First-In-First-Out). Основные операции в очереди - это добавление элемента (enqueue) и удаление элемента (dequeue). Очередь также может быть реализована с использованием массива или связанного списка.

   - Сфера применения: Очереди широко применяются в различных областях, таких как обработка задач, планирование, управление ресурсами и другие сценарии, где необходимо обеспечить порядок выполнения.
   - Особенности: Очереди работают по принципу "первым пришел, первым ушел" (FIFO), что означает, что первый добавленный элемент будет первым удаленным.

##### 2.2.4.1. Основные операции

- Добавление (Enqueue): Добавление элемента в очередь. O(1) - постоянная сложность, так как добавление происходит в конец очереди.
- Удаление (Dequeue): Удаление элемента из очереди. O(1) - постоянная сложность, так как удаление происходит из начала очереди.
- Проверка пустоты (Empty check): Проверка, является ли очередь пустой. O(1) - постоянная сложность, так как проверка выполняется за константное время.
- Получение первого элемента (Front): Получение значения первого элемента без его удаления. O(1) - постоянная сложность, так как доступ осуществляется к первому элементу.

##### 2.2.4.2. Пример реализации на Python

```python
from collections import deque

class Queue:
    def __init__(self):
        # Инициализируем очередь с помощью deque
        self.queue = deque()

    def enqueue(self, value):
        # Добавляем элемент в конец очереди
        self.queue.append(value)

    def dequeue(self):
        # Удаляем и возвращаем элемент из начала очереди
        if not self.is_empty():
            return self.queue.popleft()
        else:
            raise IndexError("Dequeue from empty queue")

    def peek(self):
        # Возвращаем элемент из начала очереди без удаления
        if not self.is_empty():
            return self.queue[0]
        else:
            raise IndexError("Peek from empty queue")

    def is_empty(self):
        # Проверяем, пуста ли очередь
        return len(self.queue) == 0

    def size(self):
        # Возвращаем количество элементов в очереди
        return len(self.queue)

    def __str__(self):
        # Переопределяем метод для удобного вывода
        return str(list(self.queue))


# Пример использования
q = Queue()
q.enqueue(10)
q.enqueue(20)
q.enqueue(30)

print(q)             # [10, 20, 30]
print(q.peek())      # 10

q.dequeue()
print(q)             # [20, 30]

print(q.size())      # 2
print(q.is_empty())  # False
```

#### 2.2.5. Дерево (Tree)

Дерево представляет собой иерархическую структуру данных, состоящую из узлов, где каждый узел может иметь несколько дочерних узлов. Узлы в дереве связаны между собой направленными ребрами. Дерево имеет корневой узел и листья, которые не имеют дочерних узлов. Примерами деревьев являются бинарные деревья, бинарные поисковые деревья, красно-черные деревья и др.

   - Сфера применения: Деревья используются для представления иерархических структур данных, таких как файловые системы, базы данных, алгоритмы поиска и т. д.
   - Особенности: Деревья обеспечивают эффективные операции вставки, удаления и поиска, а также поддерживают быстрый доступ к отсортированным данным.

##### 2.2.5.1. Основные операции

- Вставка (Insertion): Вставка нового узла в дерево. O(log n) - логарифмическая сложность в сбалансированном дереве поиска, таком как AVL или красно-черное дерево.
- Удаление (Deletion): Удаление узла из дерева. O(log n) - логарифмическая сложность в сбалансированном дереве поиска.
- Поиск (Search): Поиск узла в дереве по значению или ключу. O(log n) - логарифмическая сложность в сбалансированном дереве поиска.
- Обход (Traversal): Обход всех узлов дерева для выполнения определенных операций. O(n) - линейная сложность, так как нужно посетить каждый узел дерева.
- Получение размера (Size): Получение количества узлов в дереве. O(n) - линейная сложность, так как нужно посетить каждый узел дерева для подсчета размера.

##### 2.2.5.2. Пример реализации на Python

```python
class TreeNode:
    def __init__(self, value):
        # Узел хранит значение, а также ссылки на левый и правый дочерние узлы
        self.value = value
        self.left = None
        self.right = None


class BinaryTree:
    def __init__(self):
        # Инициализация пустого дерева
        self.root = None

    def insert(self, value):
        # Вставка элемента в бинарное дерево
        if self.root is None:
            self.root = TreeNode(value)
        else:
            self._insert_recursive(self.root, value)

    def _insert_recursive(self, current_node, value):
        # Рекурсивная вставка значения в дерево
        if value < current_node.value:
            if current_node.left is None:
                current_node.left = TreeNode(value)
            else:
                self._insert_recursive(current_node.left, value)
        else:
            if current_node.right is None:
                current_node.right = TreeNode(value)
            else:
                self._insert_recursive(current_node.right, value)

    def search(self, value):
        # Поиск значения в дереве
        return self._search_recursive(self.root, value)

    def _search_recursive(self, current_node, value):
        # Рекурсивный поиск значения
        if current_node is None:
            return False
        if current_node.value == value:
            return True
        elif value < current_node.value:
            return self._search_recursive(current_node.left, value)
        else:
            return self._search_recursive(current_node.right, value)

    def inorder_traversal(self):
        # Симметричный (inorder) обход дерева
        elements = []
        self._inorder_recursive(self.root, elements)
        return elements

    def _inorder_recursive(self, current_node, elements):
        # Рекурсивный симметричный обход
        if current_node:
            self._inorder_recursive(current_node.left, elements)
            elements.append(current_node.value)
            self._inorder_recursive(current_node.right, elements)

    def preorder_traversal(self):
        # Прямой (preorder) обход дерева
        elements = []
        self._preorder_recursive(self.root, elements)
        return elements

    def _preorder_recursive(self, current_node, elements):
        # Рекурсивный прямой обход
        if current_node:
            elements.append(current_node.value)
            self._preorder_recursive(current_node.left, elements)
            self._preorder_recursive(current_node.right, elements)

    def postorder_traversal(self):
        # Обратный (postorder) обход дерева
        elements = []
        self._postorder_recursive(self.root, elements)
        return elements

    def _postorder_recursive(self, current_node, elements):
        # Рекурсивный обратный обход
        if current_node:
            self._postorder_recursive(current_node.left, elements)
            self._postorder_recursive(current_node.right, elements)
            elements.append(current_node.value)


# Пример использования
bt = BinaryTree()
bt.insert(10)
bt.insert(5)
bt.insert(15)
bt.insert(3)
bt.insert(7)

print("Inorder traversal:", bt.inorder_traversal())    # [3, 5, 7, 10, 15]
print("Preorder traversal:", bt.preorder_traversal())  # [10, 5, 3, 7, 15]
print("Postorder traversal:", bt.postorder_traversal())# [3, 7, 5, 15, 10]

print("Search 7:", bt.search(7))  # True
print("Search 12:", bt.search(12)) # False
```

#### 2.2.6. Граф (Graph)

Граф представляет собой структуру данных, состоящую из вершин и ребер, которые связывают вершины между собой. Графы могут быть направленными или ненаправленными, в зависимости от того, могут ли ребра иметь однонаправленную связь или двунаправленную связь. Графы широко применяются для моделирования различных сетей и связей между объектами.

   - Сфера применения: Графы широко используются в различных областях, включая социальные сети, транспортные системы, компьютерные сети, алгоритмы маршрутизации и другие сценарии с взаимосвязанными объектами.
   - Особенности: Графы представляют собой набор вершин и ребер, которые могут быть направленными или ненаправленными. Операции над графами включают вставку вершин и ребер, удаление вершин и ребер, поиск и обход.

Структура данных граф находит широкое применение в различных областях, где необходимо представить и анализировать связи и отношения между объектами. Вот несколько примеров применения графов:

1. Социальные сети: Графы используются для представления связей между пользователями в социальных сетях. Каждый пользователь представлен вершиной, а связи между ними - ребрами. Графы позволяют анализировать структуру социальных сетей, находить важных пользователей, обнаруживать сообщества и предлагать друзей.

2. Роутинг в компьютерных сетях: Графы используются для моделирования компьютерных сетей и определения оптимальных путей передачи данных. Каждый узел сети представлен вершиной, а связи между ними - ребрами. Графы помогают определить наиболее эффективные маршруты для доставки данных.

3. Графовые базы данных: Графовая модель данных позволяет хранить и анализировать сложные структуры связанных данных, таких как социальные графы, семантические сети, географические данные и другие. Графовые базы данных позволяют выполнять эффективные запросы и операции на графах.

4. Анализ сетей: Графы используются для анализа различных типов сетей, таких как транспортные сети, электрические сети, биологические сети и т. д. Графы позволяют выявлять особенности и свойства сети, определять наиболее важные узлы и связи, исследовать потоки данных и энергии.

5. Алгоритмы маршрутизации и поиска: Графы используются в различных алгоритмах маршрутизации и поиска, таких как алгоритм Дейкстры, алгоритм A*, алгоритмы поиска в ширину и глубину. Графы позволяют эффективно находить оптимальные пути и решать задачи поиска.

В каждом из этих примеров структура данных граф используется для моделирования и анализа связей между объектами, что позволяет решать разнообразные задачи и получать ценную информацию о структуре и свойствах данных.

##### 2.2.6.1 Основные операции

- Вставка вершины и ребра: Добавление новых вершин и ребер в граф. O(1) - постоянная сложность, так как добавление происходит непосредственно в структуру данных графа.
- Удаление вершины и ребра: Удаление вершин и ребер из графа. O(1) - постоянная сложность, так как удаление происходит непосредственно из структуры данных графа.
- Поиск вершины и ребра: Поиск вершин и ребер в графе. O(n) - линейная сложность в худшем случае, так как может потребоваться просмотреть все вершины или ребра.
- Обход: Обход всех вершин и ребер графа для выполнения определенных операций. O(n + m) - сложность зависит от количества вершин (n) и ребер (m) в графе.

##### 2.2.6.2. Пример реализации на Python
Пример реализации структуры данных "Граф" (Graph) на языке Python:

```python
class Graph:
    def __init__(self):
        self.vertices = {}  # Словарь для хранения вершин и их смежных вершин

    def add_vertex(self, vertex):
        if vertex not in self.vertices:
            self.vertices[vertex] = []

    def add_edge(self, vertex1, vertex2):
        if vertex1 in self.vertices and vertex2 in self.vertices:
            self.vertices[vertex1].append(vertex2)
            self.vertices[vertex2].append(vertex1)

    def remove_vertex(self, vertex):
        if vertex in self.vertices:
            del self.vertices[vertex]
            # Удаляем все ребра, связанные с этой вершиной
            for adjacent_vertex in self.vertices.values():
                if vertex in adjacent_vertex:
                    adjacent_vertex.remove(vertex)

    def remove_edge(self, vertex1, vertex2):
        if vertex1 in self.vertices and vertex2 in self.vertices:
            if vertex2 in self.vertices[vertex1]:
                self.vertices[vertex1].remove(vertex2)
            if vertex1 in self.vertices[vertex2]:
                self.vertices[vertex2].remove(vertex1)

    def get_adjacent_vertices(self, vertex):
        if vertex in self.vertices:
            return self.vertices[vertex]
        return []

    def __str__(self):
        result = ""
        for vertex, adjacent_vertices in self.vertices.items():
            result += f"{vertex}: {', '.join(adjacent_vertices)}\n"
        return result
```

В данном примере класс `Graph` представляет структуру данных "Граф". В конструкторе `__init__` инициализируется пустой словарь `vertices`, который будет содержать вершины графа и их смежные вершины.

Метод `add_vertex` добавляет новую вершину в граф, если она еще не существует.

Метод `add_edge` добавляет ребро между двумя вершинами графа. Ребро добавляется в список смежных вершин каждой из вершин.

Методы `remove_vertex` и `remove_edge` удаляют вершину и ребро соответственно.

Метод `get_adjacent_vertices` возвращает список смежных вершин для заданной вершины.

Метод `__str__` переопределен для удобного вывода графа в виде списка вершин и их смежных вершин.

Пример использования:

```python
graph = Graph()
graph.add_vertex('A')
graph.add_vertex('B')
graph.add_vertex('C')
graph.add_edge('A', 'B')
graph.add_edge('B', 'C')
print(graph)
# Вывод:
# A: B
# B: A, C
# C: B

graph.remove_vertex('B')
print(graph)
# Вывод:
# A:
# C:
```

Это лишь некоторые из основных типов структур данных. Каждая структура данных имеет свои уникальные свойства, преимущества и ограничения, которые делают их подходящими для различных задач и сценариев. Понимание этих основных структур данных поможет вам выбирать наиболее подходящую структуру для решения конкретных задач.

### 2.3. Решение задач с использованием структур данных

Структуры данных играют важную роль при решении различных задач. Вот несколько примеров использования структур данных для решения задач:

1. Задача: Проверка сбалансированности скобок
   - Структура данных: Стек
   - Решение: Используйте стек для проверки сбалансированности скобок в выражении. При обнаружении открывающей скобки добавляйте ее в стек, а при обнаружении закрывающей скобки проверяйте, соответствует ли ей последняя открытая скобка в стеке. Если да, удаляйте открытую скобку из стека. После обработки всех символов в выражении проверьте, пуст ли стек. Если стек пуст, то скобки сбалансированы.

2. Задача: Поиск наиболее часто встречающегося элемента в массиве
   - Структура данных: Хэш-таблица
   - Решение: Создайте хэш-таблицу, где ключами будут элементы из массива, а значениями — количество их появлений. Пройдитесь по массиву, увеличивая счетчик для каждого элемента в хэш-таблице. Затем найдите элемент с наибольшим счетчиком.

3. Задача: Поиск кратчайшего пути в графе
   - Структура данных: Очередь (Queue) или Приоритетная очередь (Priority Queue)
   - Решение: Используйте алгоритм обхода графа в ширину (BFS) или алгоритм Дейкстры для поиска кратчайшего пути в графе. В обоих случаях можно использовать очередь или приоритетную очередь для хранения вершин, которые нужно посетить. По мере обхода графа обновляйте расстояния до каждой вершины и добавляйте их в очередь или приоритетную очередь в соответствии с их приоритетом.

4. Задача: Реализация кэша с ограниченной емкостью
   - Структура данных: Хэш-таблица и Двусвязный список
   - Решение: Используйте хэш-таблицу для быстрого доступа к данным и двусвязный список для отслеживания порядка использования данных. Когда происходит чтение данных, проверьте их наличие в кэше по ключу в хэш-таблице и переместите соответствующую запись в

 начало списка. При записи новых данных добавьте их в кэш, возможно удалив самую старую запись из конца списка, если достигнута максимальная емкость кэша.

Это лишь несколько примеров использования структур данных при решении задач. В каждом конкретном случае выбор подходящей структуры данных зависит от требований задачи и эффективности выполнения операций, необходимых для решения задачи.

## 3. Алгоритмы сортировки

### 3.1. Общие понятия

При изучении алгоритмов сортировки полезно знать следующие аспекты:

1. Описание алгоритма: Понимание того, как работает конкретный алгоритм сортировки, его принципы и шаги выполнения. Некоторые из популярных алгоритмов сортировки включают сортировку пузырьком, сортировку выбором, сортировку вставками, сортировку слиянием, быструю сортировку и сортировку подсчетом.

2. Временная сложность: Знание временной сложности алгоритма сортировки позволяет оценить его эффективность и производительность. Некоторые алгоритмы, такие как сортировка слиянием и быстрая сортировка, имеют временную сложность O(n log n), что является оптимальным для сортировки в среднем случае.

3. Пространственная сложность: Знание пространственной сложности алгоритма сортировки помогает определить, сколько дополнительной памяти требуется для выполнения сортировки. Некоторые алгоритмы, такие как сортировка слиянием и сортировка подсчетом, требуют дополнительной памяти, в то время как другие, например, быстрая сортировка, могут выполняться с использованием ограниченного объема памяти.

4. Стабильность: Понимание, является ли алгоритм сортировки стабильным или нестабильным. Стабильный алгоритм сортировки сохраняет относительный порядок элементов с одинаковыми ключами, тогда как нестабильный алгоритм может менять порядок элементов с одинаковыми ключами.

5. Лучший, средний и худший случаи: Знание производительности алгоритма сортировки в различных случаях помогает оценить его эффективность в различных сценариях. Некоторые алгоритмы имеют разные временные сложности в лучшем, среднем и худшем случаях. Например, быстрая сортировка может быть очень быстрой в среднем случае, но иметь квадратичную сложность в худшем случае.

6. Применение и ограничения: Понимание, для каких типов данных и ситуаций конкретный алгоритм сортировки наиболее подходит, а также его ограничения, может помочь выбрать правильный алгоритм для конкретной задачи.

Изучение этих аспектов поможет вам лучше понять и применять алгоритмы сортировки в различных сценариях.

### 3.2. Перечень алгоритмов сортировки

Основные алгоритмы сортировки включают:

1. Сортировка пузырьком (Bubble Sort): Проходит по массиву и меняет местами соседние элементы, если они находятся в неправильном порядке. Повторяет этот процесс до тех пор, пока весь массив не будет отсортирован.

2. Сортировка выбором (Selection Sort): Ищет наименьший элемент в массиве и помещает его в начало. Затем ищет следующий наименьший элемент и помещает его на вторую позицию, и так далее. Повторяет этот процесс до тех пор, пока весь массив не будет отсортирован.

3. Сортировка вставками (Insertion Sort): Постепенно строит отсортированную последовательность, вставляя каждый элемент на правильное место в уже отсортированной части массива. Повторяет этот процесс до тех пор, пока весь массив не будет отсортирован.

4. Быстрая сортировка (Quick Sort): Разделяет массив на две части относительно опорного элемента, перемещая элементы, меньшие опорного, влево, а элементы, большие опорного, вправо. Затем рекурсивно применяет этот процесс к двум подмассивам. В итоге, массив будет отсортирован.

5. Сортировка слиянием (Merge Sort): Рекурсивно разделяет массив пополам до единичных элементов, затем последовательно сливает их, сравнивая и располагая их в правильном порядке. Повторяет этот процесс до тех пор, пока весь массив не будет отсортирован.

6. Сортировка подсчетом (Counting Sort): Подходит для сортировки целых чисел в заданном диапазоне. Подсчитывает количество каждого значения и строит массив счетчиков. Затем использует эту информацию для правильного расположения элементов в отсортированном массиве.

7. Сортировка кучей (Heap Sort): Построение бинарной кучи из массива и последовательное извлечение наибольшего элемента, что приводит к упорядоченному массиву.

8. Сортировка радиксная (Radix Sort): Сортирует элементы по разрядам, начиная с младших разрядов и двигаясь к старшим разрядам.

Каждый из этих алгоритмов имеет свои особенности, преимущества и недостатки. Выбор конкретного алгоритма зависит от размера входных данных, типа данных, требуемой производительности и других факторов.

#### 3.2.1. Сортировка пузырьком (Bubble Sort)

Сортировка пузырьком (Bubble Sort) - это простой алгоритм сортировки, который проходит по массиву несколько раз, сравнивая и меняя местами соседние элементы, если они находятся в неправильном порядке. На каждой итерации самый большой элемент "всплывает" на правильное место, подобно пузырьку, всплывающему на поверхность.

Принцип работы алгоритма:
1. Проходим по массиву от начала до конца.
2. Сравниваем текущий элемент со следующим элементом.
3. Если текущий элемент больше следующего, меняем их местами.
4. Повторяем этот процесс для каждой пары элементов в массиве.
5. После первого прохода самый большой элемент будет находиться в конце массива.
6. Повторяем проходы по массиву до тех пор, пока все элементы не будут отсортированы.

Сложность алгоритма:
- В худшем и среднем случаях, время выполнения сортировки пузырьком составляет O(n^2), где n - количество элементов в массиве. Это означает, что время выполнения увеличивается квадратично с ростом размера массива.
- В лучшем случае, когда массив уже отсортирован, время выполнения будет O(n), но такие случаи редки.
- Сортировка пузырьком также требует дополнительной памяти для временного хранения элементов при обмене.

Из-за своей простоты и неэффективности для больших массивов, сортировка пузырьком обычно используется для обучения и демонстрации основных концепций сортировки, но не рекомендуется для практического использования при больших объемах данных.

##### 3.2.1.1. Пример на PHP

Вот простой пример реализации сортировки пузырьком на PHP:

```php
function bubbleSort(arr) {
    n = count(arr)
    
    for (i = 0 i < n - 1 i++) {
        # Флаг для оптимизации: если на текущей итерации не было обменов, значит массив уже отсортирован
        swapped = false
        
        for (j = 0 j < n - i - 1 j++) {
            if (arr[j] > arr[j + 1]) {
                # Меняем местами элементы
                temp = arr[j]
                arr[j] = arr[j + 1]
                arr[j + 1] = temp
                
                swapped = true
            }
        }
        
        # Если на текущей итерации не было обменов, значит массив уже отсортирован
        if (!swapped) {
            break
        }
    }
    
    return arr
}

# Пример использования
array = [5, 3, 8, 2, 1, 4]
sortedArray = bubbleSort(array)

# Вывод отсортированного массива
print(implode(", ", sortedArray)
```

В данном примере функция `bubbleSort` принимает массив в качестве аргумента и возвращает отсортированный массив с помощью алгоритма сортировки пузырьком. В основном цикле сортировки используются два вложенных цикла: внешний цикл для прохода по всем элементам массива, а внутренний цикл для сравнения и обмена соседних элементов. В случае, если на текущей итерации не происходит обменов, сортировка прекращается, так как массив уже отсортирован.

##### 3.2.1.2. Пример на Python

Вот пример реализации сортировки пузырьком на языке Python:

```python
def bubble_sort(arr):
    n = len(arr)

    # Проходим по массиву n-1 раз
    for i in range(n - 1):
        # Каждый проход сравниваем пары соседних элементов
        # и меняем их местами, если они находятся в неправильном порядке
        for j in range(n - i - 1):
            if arr[j] > arr[j + 1]:
                arr[j], arr[j + 1] = arr[j + 1], arr[j]

    return arr

# Пример использования
my_arr = [5, 2, 8, 12, 3]
sorted_arr = bubble_sort(my_arr)
print(sorted_arr)
```

В этом примере мы определяем функцию `bubble_sort`, которая принимает массив `arr` и сортирует его методом сортировки пузырьком. Внутри функции мы используем два вложенных цикла: внешний цикл отвечает за проходы по массиву, а внутренний цикл сравнивает и меняет местами пары соседних элементов.

Массив `[5, 2, 8, 12, 3]` сортируется в порядке возрастания, и результат выводится на экран:

```
[2, 3, 5, 8, 12]
```

Таким образом, сортировка пузырьком последовательно преобразует массив до тех пор, пока все элементы не будут отсортированы в правильном порядке.

#### 3.2.2. Сортировка выбором (Selection Sort)

Сортировка выбором (Selection Sort) - это простой алгоритм сортировки, который на каждой итерации выбирает наименьший (или наибольший) элемент из неотсортированной части массива и помещает его в правильную позицию. Принцип работы алгоритма заключается в поиске минимального (или максимального) элемента и обмене его с текущим элементом.

Принцип работы алгоритма:
1. Инициализируем переменную `min_index` со значением первого элемента массива.
2. Проходим по неотсортированной части массива, начиная со второго элемента.
3. Сравниваем каждый элемент с текущим минимальным элементом, обновляя `min_index`, если находим элемент меньший (или больший, в зависимости от порядка сортировки).
4. По завершении прохода по неотсортированной части обмениваем элемент на позиции `min_index` с первым элементом неотсортированной части, устанавливая его на своё место в отсортированной части массива.
5. Повторяем шаги 2-4 до тех пор, пока не будет отсортирована вся последовательность.

Сложность алгоритма:
- В худшем, среднем и лучшем случаях, время выполнения сортировки выбором составляет O(n^2), где n - количество элементов в массиве. Это означает, что время выполнения увеличивается квадратично с ростом размера массива.
- Поскольку сортировка выбором осуществляет прямой обмен элементов, независимо от их исходного порядка, сложность алгоритма не зависит от упорядоченности данных.
- Сортировка выбором не требует дополнительной памяти, кроме нескольких переменных для хранения индексов и временного обмена элементов.

Сортировка выбором проста в реализации, но не является эффективной для больших массивов данных, особенно по сравнению с более сложными алгоритмами сортировки, такими как быстрая сортировка или сортировка слиянием. Однако она может быть полезной в случаях, когда требуется минимальная дополнительная память и простота реализации более важны, чем производительность.

##### 3.2.2.1. Пример на PHP

Вот пример реализации сортировки выбором на языке PHP:

```php
function selectionSort(arr) {
    n = count(arr)

    # Проходим по массиву
    for (i = 0 i < n - 1 i++) {
        # Инициализируем переменную для хранения индекса минимального элемента
        minIndex = i

        # Находим минимальный элемент в неотсортированной части массива
        for (j = i + 1 j < n j++) {
            if (arr[j] < arr[minIndex]) {
                minIndex = j
            }
        }

        # Обмениваем минимальный элемент с текущим элементом
        temp = arr[i]
        arr[i] = arr[minIndex]
        arr[minIndex] = temp
    }

    return arr
}

# Пример использования
myArr = [5, 2, 8, 12, 3]
sortedArr = selectionSort(myArr)
print_r(sortedArr)
```

В этом примере мы определяем функцию `selectionSort`, которая принимает массив `arr` и сортирует его методом сортировки выбором. Внутри функции мы используем два вложенных цикла: внешний цикл отвечает за проходы по массиву, а внутренний цикл находит минимальный элемент в неотсортированной части массива.

Массив `[5, 2, 8, 12, 3]` сортируется в порядке возрастания, и результат выводится на экран:

```
Array
(
    [0] => 2
    [1] => 3
    [2] => 5
    [3] => 8
    [4] => 12
)
```

Таким образом, сортировка выбором находит наименьший элемент и помещает его в правильную позицию на каждой итерации, последовательно преобразуя массив до тех пор, пока все элементы не будут отсортированы в правильном порядке.

##### 3.2.2.2. Пример на Python

Вот пример реализации сортировки выбором на языке Python:

```python
def selection_sort(arr):
    n = len(arr)

    # Проходим по массиву
    for i in range(n-1):
        # Ищем наименьший элемент в неотсортированной части массива
        min_index = i
        for j in range(i+1, n):
            if arr[j] < arr[min_index]:
                min_index = j

        # Обмениваем наименьший элемент с текущим элементом
        arr[i], arr[min_index] = arr[min_index], arr[i]

    return arr

# Пример использования
my_arr = [5, 2, 8, 12, 3]
sorted_arr = selection_sort(my_arr)
print(sorted_arr)
```

В этом примере мы определяем функцию `selection_sort`, которая принимает массив `arr` и сортирует его методом сортировки выбором. Внутри функции мы используем два вложенных цикла: внешний цикл отвечает за проходы по массиву, а внутренний цикл находит наименьший элемент в неотсортированной части массива.

Массив `[5, 2, 8, 12, 3]` сортируется в порядке возрастания, и результат выводится на экран:

```
[2, 3, 5, 8, 12]
```

Таким образом, сортировка выбором находит наименьший элемент и помещает его в правильную позицию на каждой итерации, последовательно преобразуя массив до тех пор, пока все элементы не будут отсортированы в правильном порядке.

#### 3.2.3. Сортировка вставками (Insertion Sort)

Сортировка вставками (Insertion Sort) - это алгоритм сортировки, который работает по принципу "вставки". Он просматривает элементы массива по одному и вставляет каждый элемент в правильную позицию в уже отсортированной части массива.

Принцип работы алгоритма:
1. Начинаем с первого элемента массива и считаем, что этот элемент уже отсортирован.
2. Берем следующий элемент и вставляем его в правильную позицию в отсортированной части массива, сравнивая его со всеми предыдущими элементами и перемещая элементы, которые больше него, на одну позицию вправо.
3. Повторяем шаг 2 для всех оставшихся элементов массива, последовательно увеличивая отсортированную часть.

Сложность алгоритма сортировки вставками:
- В лучшем случае, когда массив уже отсортирован, сложность алгоритма будет O(n), где n - количество элементов в массиве.
- В худшем случае, когда массив отсортирован в обратном порядке, сложность алгоритма будет O(n^2).
- В среднем случае сложность также составляет O(n^2).

Однако, сортировка вставками эффективна для небольших массивов или уже частично отсортированных массивов. Она также является стабильной сортировкой, что означает, что она сохраняет относительный порядок равных элементов в исходном массиве.

##### 3.2.3.1. Пример на PHP

Вот пример реализации сортировки вставками на языке PHP:

```php
function insertionSort(arr) {
    n = count(arr)

    # Проходим по массиву
    for (i = 1 i < n i++) {
        key = arr[i]
        j = i - 1

        # Сдвигаем все элементы больше key на одну позицию вправо
        while (j >= 0 && arr[j] > key) {
            arr[j + 1] = arr[j]
            j = j - 1
        }

        # Вставляем key в правильную позицию
        arr[j + 1] = key
    }

    return arr
}

# Пример использования
myArr = [5, 2, 8, 12, 3]
sortedArr = insertionSort(myArr)
print_r(sortedArr)
```

В этом примере мы определяем функцию `insertionSort`, которая принимает массив `arr` и сортирует его методом сортировки вставками. Внутри функции мы используем цикл `for` для прохода по массиву. На каждой итерации мы выбираем элемент `key` и сдвигаем все элементы больше `key` на одну позицию вправо, чтобы освободить место для вставки `key` в правильную позицию.

Массив `[5, 2, 8, 12, 3]` сортируется в порядке возрастания, и результат выводится на экран:

```
Array
(
    [0] => 2
    [1] => 3
    [2] => 5
    [3] => 8
    [4] => 12
)
```

Таким образом, сортировка вставками постепенно строит отсортированную часть массива, вставляя каждый элемент в правильную позицию в уже отсортированной части.

##### 3.2.3.2. Пример на Python

Вот пример реализации сортировки вставками на языке Python:

```python
def insertion_sort(arr):
    n = len(arr)

    # Проходим по массиву, начиная со второго элемента
    for i in range(1, n):
        key = arr[i]
        j = i - 1

        # Сдвигаем все элементы, большие key, на одну позицию вправо
        while j >= 0 and arr[j] > key:
            arr[j + 1] = arr[j]
            j -= 1

        # Вставляем key в правильную позицию
        arr[j + 1] = key

    return arr

# Пример использования
my_arr = [5, 2, 8, 12, 3]
sorted_arr = insertion_sort(my_arr)
print(sorted_arr)
```

В этом примере мы определяем функцию `insertion_sort`, которая принимает массив `arr` и сортирует его методом сортировки вставками. Внутри функции мы используем цикл `for` для прохода по массиву, начиная со второго элемента. На каждой итерации мы выбираем элемент `key` и сдвигаем все элементы, которые больше `key`, на одну позицию вправо, чтобы освободить место для вставки `key` в правильную позицию.

Массив `[5, 2, 8, 12, 3]` сортируется в порядке возрастания, и результат выводится на экран:

```
[2, 3, 5, 8, 12]
```

Таким образом, сортировка вставками постепенно строит отсортированную часть массива, вставляя каждый элемент в правильную позицию в уже отсортированной части.

#### 3.2.4. Быстрая сортировка (Quick Sort)

Быстрая сортировка (Quick Sort) - это эффективный алгоритм сортировки, который основан на принципе "разделяй и властвуй". Он использует стратегию рекурсивного разделения массива на подмассивы, сортирует их отдельно и затем объединяет весь массив в отсортированный вид.

Принцип работы алгоритма:
1. Выбирается элемент массива, называемый опорным элементом (pivot). Обычно выбирается первый, последний или случайный элемент.
2. Все элементы, меньшие опорного элемента, перемещаются перед ним, а все элементы, большие или равные опорному, перемещаются после него. Этот процесс называется разделением или перестановкой.
3. Рекурсивно применяем шаги 1 и 2 к подмассивам, расположенным слева и справа от опорного элемента, пока подмассивы не будут содержать менее двух элементов.
4. Объединяем отсортированные подмассивы с опорным элементом в итоговый отсортированный массив.

Сложность алгоритма быстрой сортировки:
- В среднем случае, сложность алгоритма составляет O(n log n), где n - количество элементов в массиве.
- В худшем случае, когда массив уже отсортирован или содержит много повторяющихся элементов, сложность может составлять O(n^2).
- В лучшем случае, когда опорный элемент каждый раз делит массив на две равные части, сложность также составляет O(n log n).

Быстрая сортировка является одним из самых быстрых алгоритмов сортировки в среднем случае, и часто используется в практике программирования.

##### 3.2.4.1. Пример на PHP

Вот пример реализации быстрой сортировки (Quick Sort) на языке PHP:

```php
function quickSort(arr) {
    # Базовый случай: если массив пуст или содержит только один элемент, возвращаем его
    length = count(arr)
    if (length <= 1) {
        return arr
    }
  
    # Выбираем опорный элемент
    pivot = arr[0]
  
    # Инициализируем массивы для меньших и больших элементов
    less = []
    greater = []
  
    # Разделяем массив на две части
    for (i = 1 i < length i++) {
        if (arr[i] <= pivot) {
            less[] = arr[i]
        } else {
            greater[] = arr[i]
        }
    }
  
    # Рекурсивно применяем быструю сортировку к подмассивам и объединяем результаты
    return array_merge(quickSort(less), [pivot], quickSort(greater))
}

# Пример использования
myArr = [5, 2, 8, 12, 3]
sortedArr = quickSort(myArr)
print_r(sortedArr)
```

В этом примере мы определяем функцию `quickSort`, которая принимает массив `arr` и сортирует его методом быстрой сортировки. Внутри функции мы выбираем первый элемент массива в качестве опорного элемента (pivot) и разделяем массив на две части - одну с элементами, меньшими или равными опорному, и другую с элементами, большими опорного элемента. Затем мы рекурсивно применяем быструю сортировку к обоим подмассивам и объединяем результаты.

Массив `[5, 2, 8, 12, 3]` сортируется в порядке возрастания, и результат выводится на экран:

```
Array
(
    [0] => 2
    [1] => 3
    [2] => 5
    [3] => 8
    [4] => 12
)
```

Таким образом, быстрая сортировка разделяет массив на подмассивы, сортирует их отдельно и объединяет результаты, чтобы получить отсортированный массив.

##### 3.2.4.2. Пример на Python

Вот пример реализации быстрой сортировки (Quick Sort) на языке Python:

```python
def quick_sort(arr):
    if len(arr) <= 1:
        return arr

    pivot = arr[0]  # Опорный элемент
    lesser = [x for x in arr[1:] if x <= pivot]
    greater = [x for x in arr[1:] if x > pivot]

    return quick_sort(lesser) + [pivot] + quick_sort(greater)

# Пример использования
my_arr = [5, 2, 8, 12, 3]
sorted_arr = quick_sort(my_arr)
print(sorted_arr)
```

В этом примере мы определяем функцию `quick_sort`, которая принимает массив `arr` и сортирует его методом быстрой сортировки. 

На каждой итерации алгоритма выбирается опорный элемент `pivot`. Затем все элементы меньше или равные `pivot` помещаются в подмассив `lesser`, а все элементы больше `pivot` помещаются в подмассив `greater`. 

Затем рекурсивно применяем быструю сортировку к подмассивам `lesser` и `greater`, а результаты объединяем с опорным элементом `pivot`. 

Массив `[5, 2, 8, 12, 3]` сортируется в порядке возрастания, и результат выводится на экран:

```
[2, 3, 5, 8, 12]
```

Таким образом, быстрая сортировка разделяет массив на подмассивы, сортирует их отдельно и затем объединяет весь массив в отсортированный вид.

#### 3.2.5. Сортировка слиянием (Merge Sort)

Сортировка слиянием (Merge Sort) - это эффективный алгоритм сортировки, который основан на принципе "разделяй и властвуй". Он использует стратегию рекурсивного разделения массива на меньшие подмассивы, сортирует их отдельно, а затем объединяет отсортированные подмассивы в один отсортированный массив.

Принцип работы алгоритма:
1. Рекурсивно разделяем исходный массив пополам до тех пор, пока в каждой части не останется по одному элементу.
2. Затем производим слияние (merge) пары отсортированных подмассивов, объединяя их в один отсортированный подмассив.
3. Повторяем шаг 2 для каждой пары подмассивов и затем для следующих пар, пока не получим исходный отсортированный массив.

Сложность алгоритма сортировки слиянием:
- Временная сложность алгоритма слиянием всегда составляет O(n log n), где n - количество элементов в массиве.
- Пространственная сложность алгоритма составляет O(n), так как требуется дополнительное пространство для временных массивов при слиянии.

Сортировка слиянием обеспечивает стабильную сортировку и хорошо работает на больших массивах данных. Она часто используется в практике программирования, особенно когда требуется устойчивая сортировка или когда сортируются связные структуры данных.

##### 3.2.5.1. Пример на PHP
Вот пример реализации алгоритма сортировки слиянием (Merge Sort) на языке PHP:

```php
function mergeSort(array array)
{
    # Рекурсивная функция для разделения массива пополам
    if (count(array) <= 1) {
        return array
    }

    mid = count(array) / 2
    left = array_slice(array, 0, mid)
    right = array_slice(array, mid)

    left = mergeSort(left)
    right = mergeSort(right)

    return merge(left, right)
}

function merge(array left, array right)
{
    result = []

    while (count(left) > 0 && count(right) > 0) {
        if (left[0] <= right[0]) {
            result[] = array_shift(left)
        } else {
            result[] = array_shift(right)
        }
    }

    while (count(left) > 0) {
        result[] = array_shift(left)
    }

    while (count(right) > 0) {
        result[] = array_shift(right)
    }

    return result
}

# Пример использования
array = [8, 3, 1, 5, 2]
sortedArray = mergeSort(array)

print_r(sortedArray)
# Вывод: Array ( [0] => 1 [1] => 2 [2] => 3 [3] => 5 [4] => 8 )
```

В данном примере функция `mergeSort` реализует алгоритм сортировки слиянием. Она рекурсивно разделяет массив пополам до достижения базового случая (массив из одного элемента), а затем объединяет и сортирует полученные половины с помощью функции `merge`.

Функция `merge` принимает два отсортированных массива (`left` и `right`) и объединяет их в один отсортированный массив. Она сравнивает первые элементы каждого массива и добавляет наименьший в результат `result`. Затем она продолжает добавлять оставшиеся элементы из `left` и `right` в `result` до тех пор, пока один из массивов не будет полностью обработан.

В результате работы алгоритма мы получаем отсортированный массив `sortedArray`.

##### 3.2.5.2. Пример на Python

Пример реализации алгоритма сортировки слиянием (Merge Sort) на языке Python:

```python
def merge_sort(arr):
    if len(arr) <= 1:
        return arr

    # Разделение массива на две половины
    mid = len(arr) # 2
    left_half = arr[:mid]
    right_half = arr[mid:]

    # Рекурсивная сортировка каждой половины
    left_half = merge_sort(left_half)
    right_half = merge_sort(right_half)

    # Слияние отсортированных половин
    merged_arr = merge(left_half, right_half)

    return merged_arr


def merge(left, right):
    merged = []
    i = 0  # Индекс для обхода левой половины
    j = 0  # Индекс для обхода правой половины

    # Сравниваем элементы левой и правой половин и добавляем их в результирующий массив
    while i < len(left) and j < len(right):
        if left[i] < right[j]:
            merged.append(left[i])
            i += 1
        else:
            merged.append(right[j])
            j += 1

    # Добавляем оставшиеся элементы из левой половины
    while i < len(left):
        merged.append(left[i])
        i += 1

    # Добавляем оставшиеся элементы из правой половины
    while j < len(right):
        merged.append(right[j])
        j += 1

    return merged


# Пример использования
arr = [5, 2, 9, 1, 7, 6]
sorted_arr = merge_sort(arr)
print(sorted_arr)
# Вывод: [1, 2, 5, 6, 7, 9]
```

В данном примере функция `merge_sort` рекурсивно разделяет массив пополам, применяя сортировку слиянием для каждой половины. Затем, с помощью функции `merge`, отсортированные половины сливаются вместе, образуя отсортированный массив. Функция `merge` сравнивает элементы левой и правой половин и добавляет их в результирующий массив в порядке возрастания.

Алгоритм сортировки слиянием имеет сложность O(n log n), где n - размер массива.

#### 3.2.6. Сортировка кучей (Heap Sort)

Сортировка кучей (Heap Sort) - это алгоритм сортировки, основанный на структуре данных "куча" (heap). Он использует бинарное дерево (обычно представленное в виде массива) для представления кучи и выполняет операции перестановки элементов, чтобы упорядочить их по возрастанию или убыванию.

Принцип работы алгоритма:
1. Построение кучи: Из исходного массива строится куча. Это делается путем перестановки элементов в массиве до тех пор, пока выполняется условие кучи. Куча имеет свойство, что значение каждого узла больше или равно значения его потомков (для кучи в порядке возрастания) или меньше или равно значения его потомков (для кучи в порядке убывания).
2. Сортировка: После построения кучи наибольший (или наименьший) элемент находится в корне кучи. Этот элемент перемещается в конец массива, и корень кучи восстанавливается путем перестановки элементов до достижения условия кучи. Этот процесс повторяется для оставшихся элементов в куче до полной сортировки массива.

Сложность алгоритма сортировки кучей:
- В худшем, лучшем и среднем случае, сложность алгоритма составляет O(n log n), где n - количество элементов в массиве.
- Сортировка кучей обладает свойством "in-place", то есть требует только ограниченного дополнительного пространства, поскольку перестановки элементов выполняются непосредственно внутри исходного массива.
- Он также обладает свойством стабильности, то есть сохраняет относительный порядок элементов с одинаковыми значениями.

Сортировка кучей является эффективным алгоритмом сортировки, особенно при работе с большими наборами данных. Он широко применяется в различных областях, включая сортировку данных на диске, приоритетные очереди и поиск медианы.

##### 3.2.6.1. Пример на PHP

Вот пример реализации алгоритма сортировки кучей (Heap Sort) на PHP:

```php
function heapify(&array, length, index) {
    largest = index # Индекс текущего узла
    left = 2 * index + 1 # Индекс левого потомка
    right = 2 * index + 2 # Индекс правого потомка

    # Проверяем, является ли левый потомок больше родителя
    if (left < length && array[left] > array[largest]) {
        largest = left
    }

    # Проверяем, является ли правый потомок больше родителя
    if (right < length && array[right] > array[largest]) {
        largest = right
    }

    # Если индекс наибольшего элемента не совпадает с индексом текущего узла,
    # то меняем их местами и продолжаем просеивание вниз
    if (largest != index) {
        temp = array[index]
        array[index] = array[largest]
        array[largest] = temp

        heapify(array, length, largest)
    }
}

function heapSort(&array) {
    length = count(array)

    # Строим кучу (max heap) из массива
    for (i = length / 2 - 1 i >= 0 i--) {
        heapify(array, length, i)
    }

    # Последовательно извлекаем наибольший элемент из кучи и помещаем его в конец массива
    for (i = length - 1 i >= 0 i--) {
        temp = array[0]
        array[0] = array[i]
        array[i] = temp

        heapify(array, i, 0)
    }
}

# Пример использования
array = [9, 4, 7, 2, 1, 5, 8, 3, 6]
heapSort(array)

print(implode(', ', array) # Вывод: 1, 2, 3, 4, 5, 6, 7, 8, 9
```

В данном примере функция `heapify` выполняет операцию просеивания вниз для построения кучи, а функция `heapSort` реализует алгоритм сортировки кучей. Алгоритм сначала строит max heap из массива, затем последовательно извлекает наибольший элемент из кучи и помещает его в конец массива. В итоге получается отсортированный массив в порядке возрастания.

##### 3.2.6.2. Пример на Python

Вот пример реализации алгоритма сортировки кучей (Heap Sort) на языке Python:

```python
def heapify(arr, n, i):
    largest = i
    left = 2 * i + 1
    right = 2 * i + 2

    if left < n and arr[i] < arr[left]:
        largest = left

    if right < n and arr[largest] < arr[right]:
        largest = right

    if largest != i:
        arr[i], arr[largest] = arr[largest], arr[i]
        heapify(arr, n, largest)


def heap_sort(arr):
    n = len(arr)

    # Построение max-кучи
    for i in range(n # 2 - 1, -1, -1):
        heapify(arr, n, i)

    # Извлечение элементов из кучи один за другим
    for i in range(n - 1, 0, -1):
        arr[i], arr[0] = arr[0], arr[i]  # Свапаем корень с последним элементом
        heapify(arr, i, 0)

    return arr


# Пример использования
arr = [12, 11, 13, 5, 6, 7]
sorted_arr = heap_sort(arr)
print(sorted_arr)
# Вывод: [5, 6, 7, 11, 12, 13]
```

В этом примере функция `heapify` используется для преобразования поддерева с корнем `i` в максимальную кучу (max-heap). Функция `heap_sort` сначала строит max-кучу из заданного массива, а затем последовательно извлекает максимальный элемент из кучи и помещает его в конец массива.

Алгоритм сортировки кучей имеет сложность времени `O(n log n)`, где `n` - количество элементов в массиве.


## 4. Алгоритмы поиска

### 4.1. Общие понятия

Алгоритмы поиска относятся к основным алгоритмам, которые используются для нахождения конкретного элемента или условия в наборе данных. Они имеют важное значение при обработке и анализе данных. Ниже представлены общие понятия, связанные с алгоритмами поиска:

1. Поиск в неупорядоченном наборе данных:
   - Линейный поиск (Linear Search): Проверяет каждый элемент последовательно до нахождения искомого элемента.
   - Хеш-таблицы (Hash Tables): Используют хеш-функции для быстрого поиска элемента по его ключу.

2. Поиск в упорядоченном наборе данных:
   - Бинарный поиск (Binary Search): Работает с отсортированным набором данных и делит его пополам, чтобы искать элемент в нужной половине.
   - Интерполяционный поиск (Interpolation Search): Подобен бинарному поиску, но использует интерполяцию для нахождения более близкой к искомому значению позиции.

3. Поиск в иерархической структуре данных:
   - Обход графа (Graph Traversal): Осуществляет обход всех вершин графа для нахождения нужной информации.
   - Обход дерева (Tree Traversal): Обходит все узлы дерева в заданном порядке для нахождения нужного элемента.

Каждый алгоритм поиска имеет свою сложность, которая определяет, сколько операций требуется для выполнения поиска. Эффективный выбор алгоритма поиска зависит от размера данных, упорядоченности или структуры данных, а также требований к временной и пространственной сложности.

### 4.2. Перечень алгоритмов поиска

#### 4.2.1. Линейный поиск (Linear Search)

Линейный поиск - это простой алгоритм поиска элемента в коллекции данных. Он проверяет каждый элемент последовательно до тех пор, пока не найдет искомый элемент или не пройдет всю коллекцию.

Принцип работы:
1. Начинаем с первого элемента в коллекции.
2. Проверяем, является ли текущий элемент искомым. Если да, возвращаем его индекс или значение.
3. Если текущий элемент не является искомым, переходим к следующему элементу.
4. Повторяем шаги 2-3, пока не пройдем все элементы в коллекции или найдем искомый элемент.

Сложность: В худшем случае, когда искомый элемент находится в последней позиции или отсутствует вообще, линейный поиск должен пройти через все элементы. Поэтому его сложность поиска составляет O(n), где n - количество элементов в коллекции.

##### 4.2.1.1. Пример реализации на PHP

Вот пример реализации линейного поиска на PHP:

```php
function linearSearch(array, target) {
    length = count(array)
    for (i = 0 i < length i++) {
        if (array[i] === target) {
            return i # Искомый элемент найден, возвращаем его индекс
        }
    }
    return -1 # Искомый элемент не найден
}

# Пример использования
data = [4, 2, 9, 7, 5, 1]
target = 7

result = linearSearch(data, target)

if (result === -1) {
    print("Искомый элемент не найден"
} else {
    print("Искомый элемент найден на позиции: " . result
}
```

В данном примере функция `linearSearch` выполняет линейный поиск искомого элемента `target` в массиве `array`. Она проходит по каждому элементу массива и сравнивает его со значением `target`. Если искомый элемент найден, функция возвращает его индекс в массиве. В противном случае возвращается значение -1, указывающее на то, что искомый элемент не найден.

В приведенном примере искомым элементом является число 7. Если число 7 присутствует в массиве, то будет выведено сообщение "Искомый элемент найден на позиции: X", где X - индекс искомого элемента. В противном случае будет выведено сообщение "Искомый элемент не найден".

##### 4.2.1.2. Пример реализации на Python

Вот пример реализации линейного поиска на языке Python:

```python
def linear_search(arr, target):
    for i in range(len(arr)):
        if arr[i] == target:
            return i  # Искомый элемент найден, возвращаем его индекс
    return -1  # Искомый элемент не найден

# Пример использования
arr = [5, 2, 9, 7, 1, 6]
target = 7
result = linear_search(arr, target)
if result != -1:
    print(f"Искомый элемент {target} найден на позиции {result}.")
else:
    print(f"Искомый элемент {target} не найден.")
```

В данном примере функция `linear_search` осуществляет линейный поиск искомого элемента `target` в списке `arr`. Она перебирает элементы списка последовательно, сравнивая их с искомым элементом. Если элемент найден, функция возвращает его индекс в списке. Если элемент не найден, функция возвращает -1.

В примере используется список `[5, 2, 9, 7, 1, 6]` и ищется элемент со значением 7. Результатом выполнения программы будет вывод сообщения "Искомый элемент 7 найден на позиции 3.".

#### 4.2.2. Поиск по хэш-таблице (Hash Search)

Алгоритм поиска с использованием хэш-таблицы основан на принципе хэширования данных. Хэш-таблица представляет собой структуру данных, которая позволяет эффективно хранить и получать данные по ключу.

Описание алгоритма:
1. Создание пустой хэш-таблицы.
2. Для каждого элемента данных, которые нужно сохранить, вычисляется хэш ключа. Хэш-функция преобразует ключ в уникальное числовое значение.
3. Полученный хэш используется в качестве индекса массива, где значение элемента массива является указателем на соответствующий элемент данных.
4. При поиске элемента по ключу, выполняется хэширование ключа для определения индекса в массиве. Затем осуществляется проверка наличия элемента в этом индексе.
5. Если элемент найден, возвращается соответствующее значение. Если элемент не найден, возвращается специальное значение, обозначающее отсутствие элемента.

Применение хэш-таблиц:
- Ускорение поиска элементов по ключу, так как время поиска не зависит от размера коллекции данных.
- Уникальность ключей, что позволяет избежать дублирования данных.
- Реализация ассоциативных массивов, где значения связаны с определенными ключами.
- Решение задачи поиска и удаления элементов с временной сложностью O(1) в среднем случае.

Операции с хэш-таблицами:
- Вставка (добавление) элемента в хэш-таблицу.
- Поиск элемента по ключу.
- Удаление элемента из хэш-таблицы.

Сложность алгоритма поиска с использованием хэш-таблицы:
В идеальном случае, при хорошо спроектированной хэш-функции, время выполнения поиска будет O(1) - константной сложностью. Однако, в худшем случае, при коллизиях (когда два различных ключа имеют один и тот же хэш), время выполнения поиска может достигать O(n), где n - количество элементов в хэш-таблице.

##### 4.2.2.1. Пример реализации на PHP

Вот пример простой реализации алгоритма поиска по хэш-таблице на языке PHP:

```php
class HashTable {
    private table
    
    public function __construct() {
        this.table = []
    }
    
    public function insert(key, value) {
        hash = this.calculateHash(key)
        this.table[hash] = value
    }
    
    public function search(key) {
        hash = this.calculateHash(key)
        
        if (isset(this.table[hash])) {
            return this.table[hash]
        }
        
        return null # Key not found
    }
    
    private function calculateHash(key) {
        # Implement your own hash function here
        # For simplicity, let's use the built-in PHP function md5() as an example
        return md5(key)
    }
}

# Usage example
hashTable = new HashTable()
hashTable.insert("name", "John")
hashTable.insert("age", 30)

print(hashTable.search("name") # Output: John
print(hashTable.search("age") # Output: 30
print(hashTable.search("address") # Output: null (key not found)
```

В этом примере мы создаем класс `HashTable`, который имеет методы `insert()` для вставки пары ключ-значение в хэш-таблицу и `search()` для поиска значения по ключу. Метод `calculateHash()` вычисляет хэш для заданного ключа (в данном примере используется функция `md5()` в качестве примера хэш-функции). Хэш-таблица представлена простым массивом, где хэш служит в качестве индекса, а значение - в качестве элемента массива.

В приведенном примере мы добавляем пару ключ-значение "name"-"John" и пару "age"-30 в хэш-таблицу, а затем выполняем поиск по ключу "name" и "age", выводя соответствующие значения. Затем мы выполняем поиск по ключу "address", который отсутствует в хэш-таблице, поэтому метод `search()` возвращает `null`.

Обратите внимание, что в этом примере используется простейшая хэш-функция `md5()`, которая не является оптимальной для реальных случаев. В реальности важно выбрать хорошую хэш-функцию, которая минимизирует коллизии и обеспечивает хорошую равномерность распределения ключей по хэш-таблице.

##### 4.2.2.2. Пример реализации на Python

Вот пример простой реализации поиска по хэш-таблице на языке Python:

```python
class HashTable:
    def __init__(self):
        self.size = 10  # Размер хэш-таблицы
        self.table = [[] for _ in range(self.size)]  # Инициализация пустой хэш-таблицы

    def _hash_function(self, key):
        return key % self.size  # Пример простой хэш-функции, использующей остаток от деления

    def insert(self, key, value):
        hash_value = self._hash_function(key)
        self.table[hash_value].append((key, value))  # Добавление элемента в соответствующий список

    def search(self, key):
        hash_value = self._hash_function(key)
        for item in self.table[hash_value]:
            if item[0] == key:
                return item[1]  # Возвращаем значение, связанное с ключом
        return None  # Если элемент не найден

# Пример использования

hash_table = HashTable()
hash_table.insert(1, 'Apple')
hash_table.insert(2, 'Banana')
hash_table.insert(11, 'Orange')

print(hash_table.search(1))  # Вывод: Apple
print(hash_table.search(2))  # Вывод: Banana
print(hash_table.search(11))  # Вывод: Orange
print(hash_table.search(3))  # Вывод: None
```

В этом примере создается класс HashTable, который имеет методы `insert` для вставки элемента в хэш-таблицу и `search` для поиска значения по ключу. Хэш-таблица реализована с использованием списка списков, где каждый внутренний список представляет цепочку элементов с одинаковыми хэшами. Простая хэш-функция использует остаток от деления ключа на размер хэш-таблицы.

При вставке элемента, он хэшируется, и значение пары ключ-значение добавляется в соответствующий список в хэш-таблице. При поиске элемента, ключ также хэшируется, и производится поиск в соответствующем списке.

Обратите внимание, что этот пример представляет основную иллюстрацию и не обрабатывает коллизии или другие сложности, которые могут возникнуть в реальной реализации хэш-таблицы.

#### 4.2.3. Бинарный поиск (Binary Search)

Бинарный поиск (Binary Search) - это эффективный алгоритм поиска элемента в отсортированном массиве или списке. Он работает на основе принципа "разделяй и властвуй" и сокращает область поиска путем деления ее на половины на каждой итерации.

Принцип работы бинарного поиска:
1. Задается начальный индекс `low` и конечный индекс `high` в пределах исходного массива.
2. На каждой итерации:
   - Вычисляется средний индекс `mid` между `low` и `high`.
   - Сравнивается значение элемента в позиции `mid` с целевым значением поиска:
     - Если значение элемента равно целевому значению, возвращается индекс `mid`.
     - Если значение элемента больше целевого значения, обновляется значение `high` на `mid - 1`, чтобы сузить область поиска до нижней половины.
     - Если значение элемента меньше целевого значения, обновляется значение `low` на `mid + 1`, чтобы сузить область поиска до верхней половины.
3. Если индексы `low` и `high` пересекаются или `low` становится больше `high`, элемент не найден, и возвращается значение, указывающее на отсутствие элемента.

Сложность алгоритма бинарного поиска:
- В худшем случае время выполнения бинарного поиска составляет O(log n), где n - количество элементов в массиве или списке.
- Память, затрачиваемая на выполнение бинарного поиска, составляет O(1), так как он не требует дополнительной памяти, кроме нескольких переменных для хранения индексов.

##### 4.2.3.1. Пример реализации на PHP

Вот пример реализации бинарного поиска на языке PHP:

```php
function binarySearch(arr, target) {
    low = 0
    high = count(arr) - 1

    while (low <= high) {
        mid = (int)((low + high) / 2)

        if (arr[mid] === target) {
            return mid
        } elseif (arr[mid] < target) {
            low = mid + 1
        } else {
            high = mid - 1
        }
    }

    return -1  # Если элемент не найден
}

# Пример использования
arr = [1, 3, 5, 7, 9, 11, 13, 15]
target = 9
index = binarySearch(arr, target)

if (index !== -1) {
    print("Элемент target найден в позиции index."
} else {
    print("Элемент не найден."
}
```

В этом примере функция `binarySearch` принимает отсортированный массив `arr` и целевое значение `target`. Она выполняет бинарный поиск и возвращает индекс элемента, если он найден, или -1, если элемент отсутствует. Обратите внимание, что входной массив должен быть отсортирован для правильной работы алгоритма.

##### 4.2.3.2. Пример реализации на Python

Пример реализации бинарного поиска на языке Python:

```python
def binary_search(arr, target):
    low = 0
    high = len(arr) - 1

    while low <= high:
        mid = (low + high) # 2
        if arr[mid] == target:
            return mid
        elif arr[mid] < target:
            low = mid + 1
        else:
            high = mid - 1

    return -1  # Если элемент не найден

# Пример использования
arr = [1, 3, 5, 7, 9, 11, 13, 15]
target = 9
index = binary_search(arr, target)

if index != -1:
    print(f"Элемент {target} найден в позиции {index}.")
else:
    print("Элемент не найден.")
```

В этом примере функция `binary_search` принимает отсортированный массив `arr` и целевое значение `target`. Она выполняет бинарный поиск и возвращает индекс элемента, если он найден, или -1, если элемент отсутствует. Обратите внимание, что входной массив должен быть отсортирован для правильной работы алгоритма.

#### 4.2.4. Интерполяционный поиск (Interpolation Search)

Интерполяционный поиск (Interpolation Search) - это алгоритм поиска, который основывается на интерполяции для нахождения целевого значения в упорядоченном массиве. Он подобен бинарному поиску, но вместо постоянного деления диапазона пополам, интерполяционный поиск использует интерполяцию для более "умного" выбора следующей позиции поиска.

Принцип работы интерполяционного поиска:
1. Предполагается, что элементы в массиве равномерно распределены.
2. Вычисляется оценочная позиция для целевого значения на основе формулы: `pos = low + ((target - arr[low]) / (arr[high] - arr[low])) * (high - low)`.
   - `low` и `high` - индексы начала и конца текущего диапазона поиска.
   - `arr[low]` и `arr[high]` - значения на соответствующих позициях.
3. Если целевое значение равно `arr[pos]`, поиск завершается успешно.
4. Если целевое значение меньше `arr[pos]`, поиск продолжается в левой половине диапазона.
5. Если целевое значение больше `arr[pos]`, поиск продолжается в правой половине диапазона.
6. Шаги 2-5 повторяются, пока не будет найдено целевое значение или пока диапазон не станет пустым.

Сложность интерполяционного поиска в среднем случае составляет O(log(log(n))), где n - размер массива. Однако в худшем случае, когда значения в массиве не равномерно распределены, сложность может быть O(n).

##### 4.2.4.1. Пример реализации на PHP

Вот пример реализации интерполяционного поиска на языке PHP:

```php
function interpolationSearch(arr, target) {
    low = 0
    high = count(arr) - 1

    while (low <= high && target >= arr[low] && target <= arr[high]) {
        pos = low + ((target - arr[low]) / (arr[high] - arr[low])) * (high - low)
        pos = intval(pos) # Округляем до целого числа

        if (arr[pos] == target) {
            return pos
        } elseif (arr[pos] < target) {
            low = pos + 1
        } else {
            high = pos - 1
        }
    }

    return -1
}

# Пример использования
arr = [2, 4, 6, 8, 10, 12, 14, 16, 18, 20]
target = 10
index = interpolationSearch(arr, target)

if (index != -1) {
    print("Элемент target найден в позиции index."
} else {
    print("Элемент не найден."
}
```

В этом примере функция `interpolationSearch` принимает упорядоченный массив `arr` и целевое значение `target`. Она вычисляет оценочную позицию `pos` и сравнивает значение на этой позиции с целевым значением. Если значение найдено, возвращается соответствующий индекс. Если значение не найдено, возвращается -1.

Обратите внимание, что в PHP используется функция `intval()` для округления оценочной позиции до целого числа.

##### 4.2.4.2. Пример реализации на Python

Пример реализации интерполяционного поиска на языке Python:

```python
def interpolation_search(arr, target):
    low = 0
    high = len(arr) - 1

    while low <= high and target >= arr[low] and target <= arr[high]:
        pos = low + int(((target - arr[low]) / (arr[high] - arr[low])) * (high - low))
        if arr[pos] == target:
            return pos
        elif arr[pos] < target:
            low = pos + 1
        else:
            high = pos - 1

    return -1

# Пример использования
arr = [2, 4, 6, 8, 10, 12, 14, 16, 18, 20]
target = 10
index = interpolation_search(arr, target)

if index != -1:
    print(f"Элемент {target} найден в позиции {index}.")
else:
    print("Элемент не найден.")
```

В этом примере функция `interpolation_search` принимает упорядоченный массив `arr`

 и целевое значение `target`. Она вычисляет оценочную позицию `pos` и сравнивает значение на этой позиции с целевым значением. Если значение найдено, возвращается соответствующий индекс. Если значение не найдено, возвращается -1.

#### 4.2.5. Двоичное дерево поиска (Binary Search Tree)

Двоичное дерево поиска (Binary Search Tree) - это алгоритм поиска элемента в упорядоченном двоичном дереве. Он использует свойства двоичного дерева для эффективного поиска элемента.

Принцип работы:

1. Начинаем с корневого узла дерева.
2. Сравниваем искомый элемент с текущим узлом. Если они равны, поиск успешен и возвращаем текущий узел.
3. Если искомый элемент меньше текущего узла, переходим к левому поддереву и повторяем шаг 2.
4. Если искомый элемент больше текущего узла, переходим к правому поддереву и повторяем шаг 2.
5. Если достигнут конец поддерева (текущий узел становится нулевым), поиск завершается без успеха.

Сложность алгоритма бинарного поиска по дереву в среднем и худшем случаях составляет O(log n), где n - количество узлов в дереве. Это связано с тем, что на каждом шаге поиска мы сужаем диапазон поиска примерно вдвое.

Однако, в худшем случае, когда дерево является несбалансированным, сложность может достигать O(n), где n - количество узлов в дереве. Это происходит, когда дерево превращается в цепочку, и каждый узел имеет только одного потомка.

##### 4.2.5.1. Пример реализации на PHP

Вот пример реализации Binary Search Tree (Двоичного Дерева Поиска) на языке PHP:

```php
class TreeNode {
    public value
    public left
    public right

    public function __construct(value) {
        this.value = value
        this.left = null
        this.right = null
    }
}

class BinarySearchTree {
    public root

    public function __construct() {
        this.root = null
    }

    public function insert(value) {
        if (this.root === null) {
            this.root = new TreeNode(value)
        } else {
            this.insertRecursive(this.root, value)
        }
    }

    private function insertRecursive(&node, value) {
        if (node === null) {
            node = new TreeNode(value)
            return
        }

        if (value < node.value) {
            this.insertRecursive(node.left, value)
        } else {
            this.insertRecursive(node.right, value)
        }
    }

    public function search(value) {
        return this.searchRecursive(this.root, value)
    }

    private function searchRecursive(node, value) {
        if (node === null || node.value === value) {
            return node
        }

        if (value < node.value) {
            return this.searchRecursive(node.left, value)
        } else {
            return this.searchRecursive(node.right, value)
        }
    }

    public function remove(value) {
        this.root = this.removeRecursive(this.root, value)
    }

    private function removeRecursive(node, value) {
        if (node === null) {
            return node
        }

        if (value < node.value) {
            node.left = this.removeRecursive(node.left, value)
        } elseif (value > node.value) {
            node.right = this.removeRecursive(node.right, value)
        } else {
            if (node.left === null) {
                return node.right
            } elseif (node.right === null) {
                return node.left
            }

            node.value = this.findMin(node.right)
            node.right = this.removeRecursive(node.right, node.value)
        }

        return node
    }

    private function findMin(node) {
        while (node.left !== null) {
            node = node.left
        }
        return node.value
    }

    public function inorderTraversal() {
        result = []
        this.inorderRecursive(this.root, result)
        return result
    }

    private function inorderRecursive(node, &result) {
        if (node !== null) {
            this.inorderRecursive(node.left, result)
            result[] = node.value
            this.inorderRecursive(node.right, result)
        }
    }
}

# Пример использования

bst = new BinarySearchTree()
bst.insert(50)
bst.insert(30)
bst.insert(20)
bst.insert(40)
bst.insert(70)
bst.insert(60)
bst.insert(80)

print_r(bst.inorderTraversal())  # [20, 30, 40, 50, 60, 70, 80]

print_r(bst.search(40))  # TreeNode object with value 40

bst.remove(30)
print_r(bst.inorderTraversal())  # [20, 40, 50, 60, 70, 80]
```

В этом примере мы создаем экземпляр BinarySearchTree, вставляем несколько узлов, выполняем поиск по значению и удаляем узел. Затем мы выполняем обход дерева в порядке возрастания с помощью ин-ордер (inorder) обхода.

##### 4.2.5.2. Пример реализации на Python

Вот пример реализации Binary Search Tree на языке Python:

```python
class Node:
    def __init__(self, key):
        self.key = key
        self.left = None
        self.right = None

class BinarySearchTree:
    def __init__(self):
        self.root = None

    def insert(self, key):
        self.root = self._insert_recursive(self.root, key)

    def _insert_recursive(self, root, key):
        if root is None:
            return Node(key)
        
        if key < root.key:
            root.left = self._insert_recursive(root.left, key)
        elif key > root.key:
            root.right = self._insert_recursive(root.right, key)
        
        return root

    def search(self, key):
        return self._search_recursive(self.root, key)

    def _search_recursive(self, root, key):
        if root is None or root.key == key:
            return root
        
        if key < root.key:
            return self._search_recursive(root.left, key)
        else:
            return self._search_recursive(root.right, key)

    def delete(self, key):
        self.root = self._delete_recursive(self.root, key)

    def _delete_recursive(self, root, key):
        if root is None:
            return root
        
        if key < root.key:
            root.left = self._delete_recursive(root.left, key)
        elif key > root.key:
            root.right = self._delete_recursive(root.right, key)
        else:
            if root.left is None:
                return root.right
            elif root.right is None:
                return root.left
            
            min_node = self._find_min(root.right)
            root.key = min_node.key
            root.right = self._delete_recursive(root.right, min_node.key)

        return root

    def _find_min(self, root):
        current = root
        while current.left is not None:
            current = current.left
        return current

    def inorder_traversal(self):
        result = []
        self._inorder_recursive(self.root, result)
        return result

    def _inorder_recursive(self, root, result):
        if root is None:
            return
        
        self._inorder_recursive(root.left, result)
        result.append(root.key)
        self._inorder_recursive(root.right, result)
```

Пример использования:

```python
bst = BinarySearchTree()
bst.insert(50)
bst.insert(30)
bst.insert(20)
bst.insert(40)
bst.insert(70)
bst.insert(60)
bst.insert(80)

print(bst.inorder_traversal())  # [20, 30, 40, 50, 60, 70, 80]

print(bst.search(40))  # Node object with key 40

bst.delete(30)
print(bst.inorder_traversal())  # [20, 40, 50, 60, 70, 80]
```

В этом примере мы создаем экземпляр BinarySearchTree, вставляем несколько узлов, выполняем поиск по ключу и удаляем узел. Затем мы выполняем обход дерева в порядке возрастания с помощью ин-ордер (inorder) обхода.

### 4.3.  Алгоритмы на графах

Работа с графами включает в себя несколько основных алгоритмов. Вот некоторые из них:

1. Обход графа:
   - Поиск в глубину (Depth-First Search, DFS): алгоритм, который исследует вершины графа как можно глубже перед переходом к следующей ветви.
   - Поиск в ширину (Breadth-First Search, BFS): алгоритм, который исследует все соседние вершины перед переходом к следующему уровню графа.

2. Поиск кратчайшего пути:
   - Алгоритм Дейкстры (Dijkstra's algorithm): алгоритм для нахождения кратчайшего пути между двумя вершинами во взвешенном графе.
   - Алгоритм A* (A-star algorithm): алгоритм для нахождения кратчайшего пути между двумя вершинами с использованием эвристики для оптимизации поиска.

3. Топологическая сортировка:
   - Топологическая сортировка (Topological Sort): алгоритм для упорядочивания вершин графа таким образом, чтобы для каждого направленного ребра (u, v) вершина u предшествовала вершине v.

4. Минимальное остовное дерево:
   - Алгоритм Прима (Prim's algorithm): алгоритм для построения минимального остовного дерева во взвешенном связном графе.
   - Алгоритм Краскала (Kruskal's algorithm): алгоритм для построения минимального остовного дерева во взвешенном связном графе путем объединения непересекающихся множеств ребер.

Это лишь некоторые из основных алгоритмов работы с графами. В зависимости от конкретных задач и требований, могут быть применены и другие алгоритмы.

#### 4.3.1. Обход графа

Обход графа — это процесс посещения всех вершин графа и исследования его структуры. Он позволяет обойти все вершины графа и обработать их по определенному порядку. Существует несколько алгоритмов обхода графа, таких как поиск в глубину (DFS) и поиск в ширину (BFS).

1. Поиск в глубину (DFS):
  Алгоритм исследует граф, спускаясь "вглубь" от начальной вершины и посещая все связанные вершины до тех пор, пока не будет достигнута конечная вершина или пока не будут обойдены все вершины.

2. Поиск в ширину (BFS):
  В этом алгоритме исследование графа происходит "вширь" от начальной вершины, посещая все соседние вершины на каждом уровне перед переходом на следующий уровень.

Оба алгоритма имеют линейную сложность относительно числа вершин и ребер графа. Выбор между ними зависит от конкретной задачи и требований к обходу графа.

##### 4.3.1.1. Поиск в глубину (DFS)

Поиск в глубину (DFS, Depth-First Search) - это алгоритм обхода графа, который исследует граф до его полного исследования или до достижения целевой вершины. Принцип работы DFS заключается в последовательном исследовании вершин и их ребер, "спускаясь" вглубь графа, пока это возможно, и возвращаясь назад только после исследования всех смежных вершин.

Описание алгоритма DFS:
1. Начать с выбора стартовой вершины.
2. Посетить текущую вершину и отметить ее как посещенную.
3. Рекурсивно применить алгоритм DFS для всех смежных вершин, которые еще не были посещены.
4. Повторить шаг 3 до тех пор, пока не будут обойдены все вершины графа или пока не будет достигнута целевая вершина.

Сложность алгоритма DFS зависит от размера графа и структуры связей между вершинами. В худшем случае, если граф представляет собой полный граф, сложность будет O(V^2), где V - количество вершин в графе. Однако, если граф представляет собой разреженный граф, где количество ребер много меньше, чем количество вершин, сложность может быть выражена как O(V + E), где E - количество ребер в графе.

###### 4.3.1.1.1. Пример реализации на PHP

Вот пример реализации алгоритма поиска в глубину (DFS) на PHP:

```php
class Graph {
    private adjacencyList

    public function __construct() {
        this.adjacencyList = array()
    }

    public function addEdge(startVertex, endVertex) {
        if (!isset(this.adjacencyList[startVertex])) {
            this.adjacencyList[startVertex] = array()
        }
        this.adjacencyList[startVertex][] = endVertex
    }

    public function DFS(startVertex) {
        visited = array()
        this.DFSRecursive(startVertex, visited)
    }

    private function DFSRecursive(vertex, &visited) {
        visited[vertex] = true
        print(vertex . " "

        if (isset(this.adjacencyList[vertex])) {
            foreach (this.adjacencyList[vertex] as adjacentVertex) {
                if (!isset(visited[adjacentVertex])) {
                    this.DFSRecursive(adjacentVertex, visited)
                }
            }
        }
    }
}

# Создание графа
graph = new Graph()
graph.addEdge(1, 2)
graph.addEdge(1, 3)
graph.addEdge(2, 4)
graph.addEdge(3, 5)
graph.addEdge(4, 6)
graph.addEdge(5, 6)

# Поиск в глубину
print("DFS traversal: "
graph.DFS(1)
```

Результат выполнения данного кода будет выводить обход графа в глубину, начиная с вершины 1. Например, результат может быть следующим:

```
DFS traversal: 1 2 4 6 3 5
```

Здесь мы создаем класс `Graph`, который имеет методы `addEdge()` для добавления ребер и `DFS()` для вызова алгоритма поиска в глубину. В методе `DFS()`, мы используем вспомогательную рекурсивную функцию `DFSRecursive()`, которая посещает вершины и их смежные вершины, если они еще не были посещены. Результат обхода графа выводится на экран.

###### 4.3.1.1.2. Пример реализации на Python

Вот пример реализации алгоритма поиска в глубину (DFS) на языке Python:

```python
def dfs(graph, start, visited=None):
    if visited is None:
        visited = set()
    visited.add(start)
    print(start)  # Выводим текущую вершину
    for neighbor in graph[start]:
        if neighbor not in visited:
            dfs(graph, neighbor, visited)
```

Пример использования:

```python
# Определяем граф в виде словаря смежности
graph = {
    'A': ['B', 'C'],
    'B': ['A', 'D', 'E'],
    'C': ['A', 'F'],
    'D': ['B'],
    'E': ['B', 'F'],
    'F': ['C', 'E']
}

# Вызываем функцию DFS с начальной вершиной 'A'
dfs(graph, 'A')
```

Этот код реализует алгоритм DFS для обхода графа и выводит вершины в порядке их посещения. В каждой итерации мы добавляем текущую вершину во множество посещенных и рекурсивно вызываем функцию DFS для всех её смежных вершин, которые ещё не были посещены. Это позволяет обойти все вершины связанного графа.

##### 4.3.1.2. Поиск в ширину (BFS)

Поиск в ширину (BFS - Breadth-First Search) - это алгоритм обхода или поиска в графе, который исследует все вершины на определенном уровне перед переходом на следующий уровень. Он работает по принципу "поиск в ширину", отсюда и название.

Описание:
1. Начинаем с выбора начальной вершины и помещаем ее в очередь.
2. Пока очередь не пуста, выполняем следующие шаги:
   - Извлекаем вершину из очереди и посещаем ее.
   - Помещаем всех непосещенных соседей этой вершины в очередь.
   - Помечаем текущую вершину как посещенную.
3. Повторяем шаги 2 до тех пор, пока не будут посещены все вершины графа или не будет выполнено условие остановки.

Принцип работы:
Алгоритм BFS посещает вершины на каждом уровне графа, начиная с начальной вершины и продвигаясь в ширину по уровням. Он гарантирует, что все вершины будут обработаны на минимальном расстоянии от начальной вершины.

Сложность:
- Временная сложность: O(V + E), где V - количество вершин, E - количество ребер в графе.
- Пространственная сложность: O(V), так как используется очередь для хранения вершин.

BFS широко применяется для задач, связанных с поиском кратчайшего пути, проверкой связности графа, определением наличия циклов и других задач, требующих исследования графа в ширину.

###### 4.3.1.2.1. Пример реализации на PHP

Вот пример реализации алгоритма поиска в ширину (BFS) на языке PHP:

```php
# Python code

class Graph
{
    private adjList

    public function __construct()
    {
        this.adjList = []
    }

    public function addEdge(vertex, neighbor)
    {
        if (!isset(this.adjList[vertex])) {
            this.adjList[vertex] = []
        }

        this.adjList[vertex][] = neighbor
    }

    public function BFS(start)
    {
        visited = []
        queue = []

        visited[start] = true
        queue[] = start

        while (!empty(queue)) {
            current = array_shift(queue)
            print(current . " "

            if (isset(this.adjList[current])) {
                foreach (this.adjList[current] as neighbor) {
                    if (!isset(visited[neighbor])) {
                        visited[neighbor] = true
                        queue[] = neighbor
                    }
                }
            }
        }
    }
}

# Пример использования
graph = new Graph()

graph.addEdge(0, 1)
graph.addEdge(0, 2)
graph.addEdge(1, 2)
graph.addEdge(2, 0)
graph.addEdge(2, 3)
graph.addEdge(3, 3)

print("BFS traversal starting from vertex 2: "
graph.BFS(2)

?>
```

Результат выполнения данного кода будет:

```
BFS traversal starting from vertex 2: 2 0 3 1
```

Этот пример демонстрирует поиск в ширину, начиная с вершины 2, в графе с указанными ребрами. Алгоритм BFS использует очередь для посещения вершин и сохранения порядка обхода.

###### 4.3.1.2.2. Пример реализации на Python

Вот пример реализации алгоритма поиска в ширину (BFS) на Python:

```python
from collections import deque

def bfs(graph, start):
    visited = set()  # Множество для отслеживания посещенных вершин
    queue = deque([start])  # Очередь для обхода вершин
    
    while queue:
        vertex = queue.popleft()
        print(vertex)  # Выводим посещенную вершину
        
        if vertex not in visited:
            visited.add(vertex)  # Помечаем вершину как посещенную
            neighbors = graph[vertex]  # Получаем соседей текущей вершины
            
            for neighbor in neighbors:
                if neighbor not in visited:
                    queue.append(neighbor)  # Добавляем соседей в очередь

# Пример использования
graph = {
    'A': ['B', 'C'],
    'B': ['A', 'D', 'E'],
    'C': ['A', 'F'],
    'D': ['B'],
    'E': ['B', 'F'],
    'F': ['C', 'E']
}

bfs(graph, 'A')
```

В данном примере мы создаем граф в виде словаря, где ключами являются вершины, а значениями - списки соседних вершин. Алгоритм BFS выполняет обход графа, начиная с заданной стартовой вершины 'A'. Он использует очередь для посещения вершин в порядке их расстояния от стартовой вершины. Каждая посещенная вершина выводится на экран.

Результат работы данного примера будет:
```
A
B
C
D
E
F
```

Обратите внимание, что порядок обхода вершин может различаться в зависимости от структуры графа и порядка добавления соседей в очередь.

#### 4.3.2. Поиск кратчайшего пути

Для поиска кратчайшего пути на графах можно использовать несколько алгоритмов. Некоторые из них:

1. Алгоритм Дейкстры (Dijkstra's algorithm): Этот алгоритм находит кратчайший путь от одной начальной вершины ко всем остальным вершинам в графе с неотрицательными весами ребер. Алгоритм использует жадный подход, выбирая вершину с наименьшим расстоянием на каждом шаге.

2. Алгоритм Беллмана-Форда (Bellman-Ford algorithm): Этот алгоритм также находит кратчайший путь от одной начальной вершины ко всем остальным вершинам в графе, но он может работать с графами, в которых есть отрицательные веса ребер. Алгоритм использует динамическое программирование для постепенного улучшения расстояний до вершин.

3. Алгоритм A* (A-star algorithm): Этот алгоритм находит кратчайший путь от одной начальной вершины к целевой вершине в графе с использованием эвристической функции для оценки оставшегося расстояния до цели. Алгоритм комбинирует информацию о стоимости пути с оценкой эвристики для выбора наилучшего следующего шага.

4. Алгоритм Флойда-Уоршалла (Floyd-Warshall algorithm): Этот алгоритм находит кратчайшие пути между всеми парами вершин во взвешенном ориентированном или неориентированном графе. Алгоритм использует динамическое программирование для постепенного улучшения расстояний между всеми парами вершин.

Каждый из этих алгоритмов имеет свои особенности и применяется в разных ситуациях в зависимости от требований задачи и свойств графа.

##### 4.3.2.1. Алгоритм Дейкстры (Dijkstra's algorithm)

Алгоритм Дейкстры (Dijkstra's algorithm) - это алгоритм поиска кратчайшего пути от одной начальной вершины ко всем остальным вершинам во взвешенном графе с неотрицательными весами ребер. Алгоритм назван в честь голландского ученого Эдсгера Дейкстры, который разработал его в 1956 году.

Принцип работы алгоритма Дейкстры следующий:
1. Создать множество вершин, для которых расстояние от начальной вершины до них будет постепенно уточняться.
2. Изначально установить расстояние от начальной вершины до всех остальных вершин как "бесконечность", за исключением начальной вершины, у которой расстояние равно 0.
3. Поместить начальную вершину во множество вершин, для которых расстояние уже уточнено.
4. Для каждой смежной вершины, вычислить новое расстояние от начальной вершины через текущую вершину и сравнить его с текущим расстоянием до этой вершины. Если новое расстояние меньше, обновить значение расстояния.
5. Повторять шаг 4 для всех вершин в графе, пока не будут уточнены все расстояния.
6. После завершения алгоритма, для каждой вершины будет известно кратчайшее расстояние от начальной вершины до нее.

Сложность алгоритма Дейкстры зависит от способа реализации. В общем случае, если граф представлен с помощью списков смежности, сложность алгоритма составляет O((V + E) * log(V)), где V - количество вершин, E - количество ребер. Это связано с использованием мин-кучи (min-heap) для эффективного выбора следующей вершины с минимальным расстоянием. Однако, при использовании других структур данных, таких как массив или двоичная куча (binary heap), сложность алгоритма может быть различной.

###### 4.3.2.1.1. Пример реализации на PHP

Вот пример реализации алгоритма Дейкстры на PHP:

```php
# Python code

function dijkstra(graph, start)
{
    distances = array_fill_keys(array_keys(graph), INF) # Инициализация расстояний как бесконечность
    distances[start] = 0 # Расстояние от начальной вершины до нее самой равно 0
    visited = array() # Посещенные вершины

    while (count(visited) < count(graph)) {
        minDistance = INF
        current = null

        # Найти вершину с минимальным расстоянием из еще не посещенных
        foreach (distances as vertex => distance) {
            if (!in_array(vertex, visited) && distance < minDistance) {
                minDistance = distance
                current = vertex
            }
        }

        # Посетить текущую вершину
        visited[] = current

        # Обновить расстояния до смежных вершин
        foreach (graph[current] as neighbor => weight) {
            newDistance = distances[current] + weight
            if (newDistance < distances[neighbor]) {
                distances[neighbor] = newDistance
            }
        }
    }

    return distances
}

# Пример графа
graph = array(
    'A' => array('B' => 4, 'C' => 2),
    'B' => array('A' => 4, 'C' => 1, 'D' => 5),
    'C' => array('A' => 2, 'B' => 1, 'D' => 8),
    'D' => array('B' => 5, 'C' => 8),
)

start = 'A' # Начальная вершина

result = dijkstra(graph, start)

# Вывод результатов
foreach (result as vertex => distance) {
    print("Shortest distance from start to vertex: distance\n"
}
?>
```

В этом примере алгоритм Дейкстры реализован в виде функции `dijkstra()`. Граф представлен в виде ассоциативного массива, где ключи - вершины, а значения - ассоциативные массивы, содержащие смежные вершины и их веса. Начальная вершина передается в функцию `dijkstra()`, которая возвращает массив с кратчайшими расстояниями от начальной вершины до остальных вершин.

В данном примере используется простая реализация с использованием массивов для хранения расстояний и списка посещенных вершин. Алгоритм выбирает вершину с минимальным расстоянием из еще не посещенных и обновляет расстояния до смежных вершин, если найденное расстояние меньше текущего. Этот процесс повторяется, пока все вершины не будут посещены.

Приведенный пример решает задачу поиска кратчайших расстояний от начальной вершины 'A' до всех остальных вершин в графе.

###### 4.3.2.1.2. Пример реализации на Python

Вот пример реализации алгоритма Дейкстры на языке Python:

```python
import heapq

def dijkstra(graph, start):
    distances = {vertex: float('inf') for vertex in graph}
    distances[start] = 0

    heap = [(0, start)]
    while heap:
        current_distance, current_vertex = heapq.heappop(heap)

        # Пропускаем вершину, если мы уже нашли более короткий путь до нее
        if current_distance > distances[current_vertex]:
            continue

        for neighbor, weight in graph[current_vertex].items():
            distance = current_distance + weight

            # Если мы нашли короткий путь до соседней вершины, обновляем расстояние
            if distance < distances[neighbor]:
                distances[neighbor] = distance
                heapq.heappush(heap, (distance, neighbor))

    return distances
```

Пример использования:
```python
graph = {
    'A': {'B': 4, 'C': 2},
    'B': {'A': 4, 'C': 1, 'D': 5},
    'C': {'A': 2, 'B': 1, 'D': 8},
    'D': {'B': 5, 'C': 8}
}

start_vertex = 'A'
distances = dijkstra(graph, start_vertex)

print("Кратчайшие расстояния от вершины", start_vertex)
for vertex, distance in distances.items():
    print("До вершины", vertex, "расстояние:", distance)
```

В этом примере мы используем словарь `graph`, чтобы представить граф. Ключи словаря - это вершины графа, а значения - это словари, содержащие соседние вершины и их веса. Функция `dijkstra` принимает граф и начальную вершину, и возвращает словарь, содержащий кратчайшие расстояния от начальной вершины до каждой вершины графа.

Обратите внимание, что для эффективного выбора вершины с минимальным расстоянием мы используем мин-кучу (min-heap) из модуля `heapq`. Это позволяет нам извлекать вершины с минимальным расстоянием за время O(log(V)), где V - количество вершин.

Данный пример иллюстрирует базовую реализацию алгоритма Дейкстры, но в реальных задачах может потребоваться дополнительная логика или модификации для учета различных условий или требований.


##### 4.3.2.2. Алгоритм Беллмана-Форда (Bellman-Ford algorithm)

Алгоритм Беллмана-Форда — это алгоритм для нахождения кратчайших путей во взвешенном ориентированном графе, даже если граф содержит отрицательные ребра. Алгоритм способен обнаружить отрицательные циклы в графе.

Описание и принцип работы алгоритма:
1. Инициализируем расстояния до всех вершин графа как бесконечность, кроме начальной вершины, для которой расстояние равно 0.
2. Повторяем следующий шаг V-1 раз, где V - количество вершин в графе:
   - Проходим по каждому ребру графа и обновляем расстояния до вершин. Если найденное расстояние меньше текущего расстояния до вершины, обновляем его.
3. После V-1 итераций проверяем наличие отрицательных циклов:
   - Проходим по каждому ребру графа и снова обновляем расстояния до вершин. Если найденное расстояние меньше текущего расстояния до вершины, это означает наличие отрицательного цикла в графе.
4. Если в шаге 3 обнаружен отрицательный цикл, то алгоритм завершается с сообщением о его наличии. Иначе, полученные расстояния являются кратчайшими путями от начальной вершины до всех остальных вершин.

Сложность алгоритма Беллмана-Форда составляет O(V * E), где V - количество вершин, а E - количество ребер в графе.

Алгоритм Беллмана-Форда широко используется в задачах нахождения кратчайших путей в графах, особенно когда граф может содержать отрицательные ребра или отрицательные циклы. Он может быть применен для решения задач таких как маршрутизация в сетях, поиск кратчайшего пути в графе с отрицательными ребрами и т. д.

###### 4.3.2.2.1. Пример реализации на PHP

Вот пример реализации алгоритма Беллмана-Форда на PHP:

```php
# Python code

function bellmanFord(graph, startVertex) {
    vertices = array_keys(graph)
    distances = []
    predecessors = []

    # Инициализируем расстояния до всех вершин как бесконечность, кроме начальной вершины
    foreach (vertices as vertex) {
        distances[vertex] = INF
    }
    distances[startVertex] = 0

    # Основной шаг алгоритма
    for (i = 0 i < count(vertices) - 1 i++) {
        foreach (graph as vertex => edges) {
            foreach (edges as adjVertex => weight) {
                if (distances[vertex] != INF && distances[vertex] + weight < distances[adjVertex]) {
                    distances[adjVertex] = distances[vertex] + weight
                    predecessors[adjVertex] = vertex
                }
            }
        }
    }

    # Проверка наличия отрицательных циклов
    foreach (graph as vertex => edges) {
        foreach (edges as adjVertex => weight) {
            if (distances[vertex] != INF && distances[vertex] + weight < distances[adjVertex]) {
                return "Граф содержит отрицательный цикл"
            }
        }
    }

    # Формирование результата
    result = []
    foreach (vertices as vertex) {
        path = []
        currentVertex = vertex
        while (isset(predecessors[currentVertex])) {
            array_unshift(path, currentVertex)
            currentVertex = predecessors[currentVertex]
        }
        array_unshift(path, currentVertex)
        result[vertex] = [
            'distance' => distances[vertex],
            'path' => path
        ]
    }

    return result
}

# Пример использования
graph = [
    'A' => ['B' => 6, 'C' => 3],
    'B' => ['D' => 1],
    'C' => ['B' => 2, 'D' => 5],
    'D' => [],
]

startVertex = 'A'
result = bellmanFord(graph, startVertex)

# Вывод результата
foreach (result as vertex => data) {
    print("Кратчайшее расстояние от вершины startVertex до вершины vertex: " . data['distance'] . "\n"
    print("Кратчайший путь: " . implode(' . ', data['path']) . "\n"
    print("\n"
}
```

В данном примере предполагается, что граф представлен в виде ассоциативного массива, где ключи - это вершины, а значения - массивы ребер и их весов. Функция `bellmanFord` принимает граф и начальную вершину в качестве параметров и возвращает ассоциативный массив с кратчайшими расстояниями и путями от начальной вершины до остальных вершин графа.

Приведенный пример реализует алгоритм Беллмана-Форда для поиска кратчайших путей во взвешенном графе. Он выполняет итерации по всем ребрам графа, обновляя расстояния до вершин, пока не достигнет оптимальных значений. Затем алгоритм проверяет наличие отрицательных циклов, и если таковые обнаружены, возвращает сообщение об их наличии.

###### 4.3.2.2.2. Пример реализации на Python

Вот пример реализации алгоритма Беллмана-Форда на языке Python:

```python
from collections import defaultdict

# Класс, представляющий граф
class Graph:
    def __init__(self, vertices):
        self.V = vertices  # Количество вершин
        self.graph = []  # Список ребер

    # Добавление ребра в граф
    def add_edge(self, u, v, w):
        self.graph.append([u, v, w])

    # Функция для печати кратчайших путей
    def print_solution(self, dist):
        print("Вершина \tРасстояние от источника")
        for i in range(self.V):
            print(f"{i}\t\t{dist[i]}")

    # Алгоритм Беллмана-Форда
    def bellman_ford(self, src):
        # Инициализация расстояний до всех вершин как бесконечность
        dist = [float("Inf")] * self.V
        dist[src] = 0

        # Релаксация ребер V-1 раз
        for _ in range(self.V - 1):
            # Проходим по всем ребрам графа и обновляем расстояния
            for u, v, w in self.graph:
                if dist[u] != float("Inf") and dist[u] + w < dist[v]:
                    dist[v] = dist[u] + w

        # Проверка наличия отрицательных циклов
        for u, v, w in self.graph:
            if dist[u] != float("Inf") and dist[u] + w < dist[v]:
                print("Граф содержит отрицательный цикл")
                return

        # Печать кратчайших путей
        self.print_solution(dist)


# Пример использования
g = Graph(5)  # Создание графа с 5 вершинами

# Добавление ребер в граф
g.add_edge(0, 1, -1)
g.add_edge(0, 2, 4)
g.add_edge(1, 2, 3)
g.add_edge(1, 3, 2)
g.add_edge(1, 4, 2)
g.add_edge(3, 2, 5)
g.add_edge(3, 1, 1)
g.add_edge(4, 3, -3)

source = 0  # Начальная вершина

# Запуск алгоритма Беллмана-Форда
g.bellman_ford(source)
```

В этом примере мы создаем граф с помощью класса `Graph` и добавляем ребра с их весами. Затем мы вызываем метод `bellman_ford` для выполнения алгоритма Беллмана-Форда, указывая начальную вершину. Результатом выполнения алгоритма будет вывод кратчайших путей от начальной вершины до всех остальных вершин графа.

Обратите внимание, что если в графе присутствует отрицательный цикл, то алгоритм обнаружит его и выведет сообщение "Граф содержит отрицательный цикл".
 
##### 4.3.2.3. Алгоритм A* (A-star algorithm)

Алгоритм A* (A-star) является эффективным алгоритмом поиска пути в графе или на графе. Он сочетает в себе идеи алгоритма Дейкстры и эвристического поиска для эффективного нахождения оптимального пути от начальной вершины к целевой вершине.

Описание и принцип работы:
1. Алгоритм A* использует две оценки расстояния для каждой вершины:
   - g-значение: это фактическое расстояние от начальной вершины до текущей вершины.
   - h-значение: это эвристическая оценка расстояния от текущей вершины до целевой вершины. Она вычисляется с использованием эвристической функции, например, эвристического расстояния (например, евклидово расстояние или расстояние Манхэттена) между текущей вершиной и целевой вершиной.

2. Алгоритм использует очередь с приоритетом (обычно реализованную с помощью кучи) для выбора вершины с наименьшим значением f = g + h исходя из текущих значений g и h для каждой вершины.

3. Алгоритм продолжает итеративно извлекать вершины из очереди с приоритетом и рассматривать их соседей. Для каждого соседнего узла он обновляет значения g и h, если новые значения лучше (меньше) текущих.

4. Алгоритм продолжает выполнение до тех пор, пока не будет найден путь к целевой вершине или очередь с приоритетом не станет пустой.

Сложность алгоритма:
Сложность алгоритма A* зависит от эвристической функции и структуры графа. В лучшем случае, когда эвристическая функция адекватно оценивает расстояние до цели, сложность алгоритма A* составляет O(d), где d - длина оптимального пути. В худшем случае, когда эвристическая функция не информативна, сложность алгоритма может быть экспоненциальной - O(b^d), где b - фактор ветвления графа и d - глубина оптимального пути.

Примечание: Однако на практике алгоритм A* обычно имеет очень хорошую производительность и работает эффективно на большинстве реальных проблемных графов при правильно выбранной эвристике.

###### 4.3.2.3.1. Пример реализации на PHP

Вот пример реализации алгоритма A* на PHP:

```php
# Python code

class Node
{
    public x
    public y
    public g
    public h
    public f
    public parent

    public function __construct(x, y)
    {
        this.x = x
        this.y = y
        this.g = 0
        this.h = 0
        this.f = 0
        this.parent = null
    }
}

function heuristic(node, goal)
{
    # Эвристическая функция - евклидово расстояние между текущим узлом и целевым узлом
    dx = abs(node.x - goal.x)
    dy = abs(node.y - goal.y)
    return sqrt(dx * dx + dy * dy)
}

function AStar(start, goal)
{
    openSet = [start]
    closedSet = []

    while (!empty(openSet)) {
        # Ищем узел с наименьшим значением f
        current = openSet[0]
        currentIndex = 0
        foreach (openSet as index => node) {
            if (node.f < current.f) {
                current = node
                currentIndex = index
            }
        }

        # Проверяем, достигли ли целевого узла
        if (current === goal) {
            path = []
            while (current) {
                path[] = [current.x, current.y]
                current = current.parent
            }
            return array_reverse(path)
        }

        # Перемещаем текущий узел из открытого списка в закрытый список
        array_splice(openSet, currentIndex, 1)
        closedSet[] = current

        # Просматриваем соседние узлы текущего узла
        neighbors = getNeighbors(current) # Функция, возвращающая соседние узлы текущего узла
        foreach (neighbors as neighbor) {
            # Если соседний узел уже в закрытом списке, пропускаем его
            if (in_array(neighbor, closedSet)) {
                continue
            }

            # Расстояние от начального узла до соседнего узла
            gScore = current.g + 1

            # Если соседний узел не в открытом списке, добавляем его туда
            if (!in_array(neighbor, openSet)) {
                openSet[] = neighbor
            } elseif (gScore >= neighbor.g) {
                # Если новый путь не лучше, чем старый, пропускаем его
                continue
            }

            # Обновляем значения g, h и f для соседнего узла
            neighbor.g = gScore
            neighbor.h = heuristic(neighbor, goal)
            neighbor.f = neighbor.g + neighbor.h
            neighbor.parent = current
        }
    }

    # Если открытый список пуст и мы не достигли целевого узла, значит путь не существует
    return null
}

# Пример использования
start = new Node(0, 0)
goal = new Node(5, 5)
path = AStar(start, goal)

if (path === null) {
    print("Путь не найден."
} else {
    print("Кратчайший путь: "
    foreach (path as point) {
        print("[point[0], point[1]] "
    }
}
?>
```

Обратите внимание, что в примере реализации используются функции `heuristic()` и `getNeighbors()`, которые не представлены здесь. Вы можете определить эти функции в соответствии с вашими конкретными требованиями, чтобы они возвращали эвристическую оценку и список соседних узлов соответственно.

###### 4.3.2.3.2. Пример реализации на Python

Вот пример реализации алгоритма A* на языке Python:

```python
import heapq

def heuristic(node, goal):
    # Реализация эвристической функции
    # Возвращает оценку расстояния от текущей вершины до целевой вершины
    pass

def astar(graph, start, goal):
    # Создаем очередь с приоритетом
    open_set = []
    # Создаем словарь для отслеживания родителей вершин
    came_from = {}

    # Инициализируем значения g-значений для всех вершин как бесконечность,
    # кроме начальной вершины, у которой g-значение равно 0
    g_scores = {node: float('inf') for node in graph}
    g_scores[start] = 0

    # Инициализируем значения f-значений для всех вершин как бесконечность
    f_scores = {node: float('inf') for node in graph}
    f_scores[start] = heuristic(start, goal)

    # Добавляем начальную вершину в очередь с приоритетом
    heapq.heappush(open_set, (f_scores[start], start))

    while open_set:
        # Извлекаем вершину с наименьшим f-значением из очереди с приоритетом
        current = heapq.heappop(open_set)[1]

        if current == goal:
            # Если достигнута целевая вершина, восстанавливаем путь
            path = []
            while current in came_from:
                path.append(current)
                current = came_from[current]
            path.append(start)
            path.reverse()
            return path

        # Просматриваем соседние вершины
        for neighbor in graph[current]:
            # Расстояние от начальной вершины до соседней вершины
            g_score = g_scores[current] + graph[current][neighbor]
            if g_score < g_scores[neighbor]:
                # Обновляем значения g-значения и f-значения
                came_from[neighbor] = current
                g_scores[neighbor] = g_score
                f_scores[neighbor] = g_score + heuristic(neighbor, goal)
                # Добавляем соседнюю вершину в очередь с приоритетом
                heapq.heappush(open_set, (f_scores[neighbor], neighbor))

    # Если достижение целевой вершины невозможно, возвращаем None
    return None
```

Примечание: В этом примере предполагается, что граф представлен в виде словаря, где ключами являются вершины, а значениями - словари смежных вершин и соответствующих весов ребер. Функция `heuristic` должна быть реализована в соответствии с конкретной проблемой и возвращать оценку расстояния между вершинами.

##### 4.3.2.4. Алгоритм Флойда-Уоршалла (Floyd-Warshall algorithm)

Алгоритм Флойда-Уоршалла (Floyd-Warshall) - это алгоритм для нахождения кратчайших путей между всеми парами вершин взвешенного ориентированного графа. Он позволяет найти кратчайший путь между любыми двумя вершинами, учитывая веса ребер.

Принцип работы алгоритма Флойда-Уоршалла:

1. Алгоритм использует матрицу расстояний D размером n × n, где n - количество вершин в графе. Изначально матрица заполняется значениями расстояний между соответствующими парами вершин. Если между вершинами i и j нет ребра, то` D[i][j]` устанавливается равным бесконечности (или большому числу), чтобы указать отсутствие прямого пути между ними.

2. Далее алгоритм выполняет n итераций, на каждой из которых обновляются значения матрицы расстояний D. На каждой итерации рассматривается вершина k как промежуточная вершина между всеми парами вершин i и j. Если путь от i до j через вершину k оказывается короче, чем текущий путь от i до j, то значение `D[i][j]` обновляется на новую длину пути.

3. После выполнения всех итераций матрица D будет содержать кратчайшие пути между всеми парами вершин.

Сложность алгоритма Флойда-Уоршалла равна O(n^3), где n - количество вершин в графе. Это связано с выполнением трех вложенных циклов для обновления значений матрицы расстояний D на каждой итерации.

###### 4.3.2.4.1. Пример реализации на PHP

Вот пример реализации алгоритма Флойда-Уоршалла для структуры данных "Graph" на языке PHP:

```php
class Graph {
    private vertices
    private adjacencyMatrix
    private infinity

    public function __construct() {
        this.vertices = []
        this.adjacencyMatrix = []
        this.infinity = PHP_INT_MAX
    }

    public function addVertex(vertex) {
        if (!in_array(vertex, this.vertices)) {
            this.vertices[] = vertex
            this.updateAdjacencyMatrix()
        }
    }

    public function addEdge(vertex1, vertex2, weight) {
        index1 = array_search(vertex1, this.vertices)
        index2 = array_search(vertex2, this.vertices)

        if (index1 !== false && index2 !== false) {
            this.adjacencyMatrix[index1][index2] = weight
        }
    }

    public function getVertices() {
        return this.vertices
    }

    public function getAdjacencyMatrix() {
        return this.adjacencyMatrix
    }

    public function floydWarshall() {
        distances = this.adjacencyMatrix

        vertexCount = count(this.vertices)
        for (k = 0 k < vertexCount k++) {
            for (i = 0 i < vertexCount i++) {
                for (j = 0 j < vertexCount j++) {
                    if (distances[i][k] !== this.infinity && distances[k][j] !== this.infinity) {
                        distances[i][j] = min(distances[i][j], distances[i][k] + distances[k][j])
                    }
                }
            }
        }

        return distances
    }

    private function updateAdjacencyMatrix() {
        vertexCount = count(this.vertices)
        this.adjacencyMatrix = array_fill(0, vertexCount, array_fill(0, vertexCount, this.infinity))
    }
}
```

Пример использования:

```php
graph = new Graph()

graph.addVertex("A")
graph.addVertex("B")
graph.addVertex("C")
graph.addVertex("D")

graph.addEdge("A", "B", 2)
graph.addEdge("A", "C", 4)
graph.addEdge("B", "D", 3)
graph.addEdge("C", "D", 1)

distances = graph.floydWarshall()

# Выводим матрицу расстояний
vertices = graph.getVertices()
vertexCount = count(vertices)

print("    "
for (i = 0 i < vertexCount i++) {
    print(vertices[i] . " "
}
print("\n"

for (i = 0 i < vertexCount i++) {
    print(vertices[i] . " "
    for (j = 0 j < vertexCount j++) {
        print((distances[i][j] === graph.infinity ? "∞" : distances[i][j]) . " "
    }
    print("\n"
}
```

Этот пример создает граф с 4 вершинами (A, B, C, D) и 4 ребрами с весами, затем выполняет алгоритм Флойда-Уоршалла для поиска кратчайших путей между всеми парами вершин. Результатом является матрица расстояний между каждой парой вершин графа.

###### 4.3.2.4.2. Пример реализации на Python

Вот пример реализации алгоритма Флойда-Уоршалла на языке Python:

```python
import sys

class Graph:
    def __init__(self, vertices):
        self.V = vertices
        self.INF = sys.maxsize
        self.graph = [[self.INF] * self.V for _ in range(self.V)]

    def add_edge(self, u, v, weight):
        self.graph[u][v] = weight

    def floyd_warshall(self):
        distances = self.graph.copy()

        for k in range(self.V):
            for i in range(self.V):
                for j in range(self.V):
                    distances[i][j] = min(distances[i][j], distances[i][k] + distances[k][j])

        return distances

# Пример использования
g = Graph(4)
g.add_edge(0, 1, 2)
g.add_edge(0, 2, 4)
g.add_edge(1, 3, 3)
g.add_edge(2, 3, 1)

distances = g.floyd_warshall()

# Выводим матрицу расстояний
for i in range(g.V):
    for j in range(g.V):
        if distances[i][j] == g.INF:
            print("∞", end=" ")
        else:
            print(distances[i][j], end=" ")
    print()
```

В этом примере создается граф с 4 вершинами (нумерация с 0 до 3) и 4 ребрами с весами. Затем выполняется алгоритм Флойда-Уоршалла для поиска кратчайших путей между всеми парами вершин. Результатом является матрица расстояний, где значение INF представляет бесконечность.

#### 4.3.3. Топологическая сортировка

Топологическая сортировка графов - это алгоритм для линейной упорядочивания вершин в ориентированном ациклическом графе (DAG). Она определяет порядок обработки вершин таким образом, что все ребра указывают от более ранней вершины к более поздней.

Принцип работы топологической сортировки:

1. Выберите любую вершину в графе, которая не имеет входящих ребер, и поместите ее в результат.
2. Удалите выбранную вершину из графа вместе со всеми исходящими из нее ребрами.
3. Повторяйте шаги 1 и 2, пока в графе остаются вершины.
4. Когда все вершины обработаны, результатом будет последовательность вершин, которая представляет собой топологический порядок сортировки.

Сложность алгоритма топологической сортировки зависит от количества вершин и ребер в графе. Обозначим число вершин как V, а число ребер как E.

- Временная сложность: O(V + E), так как каждая вершина и каждое ребро обрабатываются ровно один раз.
- Пространственная сложность: O(V), так как используется дополнительное хранилище для сохранения упорядоченных вершин.

Топологическая сортировка широко применяется в задачах, связанных с зависимостями и порядком выполнения. Некоторые примеры применения включают планирование задач, определение порядка выполнения операций, управление зависимостями в проектах и другие.

##### 4.3.3.1. Пример реализации на PHP

Вот пример реализации алгоритма топологической сортировки на PHP:

```php
# Python code

class Graph {
    private adjacencyList

    public function __construct() {
        this.adjacencyList = []
    }

    public function addVertex(vertex) {
        this.adjacencyList[vertex] = []
    }

    public function addEdge(start, end) {
        this.adjacencyList[start][] = end
    }

    public function topologicalSort() {
        visited = []
        stack = []

        foreach (this.adjacencyList as vertex => neighbors) {
            if (!isset(visited[vertex])) {
                this.dfs(vertex, visited, stack)
            }
        }

        return array_reverse(stack)
    }

    private function dfs(vertex, &visited, &stack) {
        visited[vertex] = true

        foreach (this.adjacencyList[vertex] as neighbor) {
            if (!isset(visited[neighbor])) {
                this.dfs(neighbor, visited, stack)
            }
        }

        stack[] = vertex
    }
}

# Пример использования
graph = new Graph()

graph.addVertex('A')
graph.addVertex('B')
graph.addVertex('C')
graph.addVertex('D')
graph.addVertex('E')

graph.addEdge('A', 'C')
graph.addEdge('C', 'E')
graph.addEdge('B', 'D')
graph.addEdge('D', 'E')
graph.addEdge('A', 'B')

sortedVertices = graph.topologicalSort()

print(implode(' . ', sortedVertices) # Выводит: A . B . C . D . E

?>
```

В этом примере мы создаем класс `Graph`, который представляет граф и имеет методы для добавления вершин и ребер. Метод `topologicalSort()` реализует алгоритм топологической сортировки с помощью обхода в глубину (DFS). В итоге мы получаем упорядоченный массив вершин, который представляет топологический порядок сортировки.

В нашем примере граф содержит вершины A, B, C, D и E, а ребра определены между ними. Результатом работы алгоритма будет вывод в консоль упорядоченной последовательности вершин: A . B . C . D . E.

##### 4.3.3.2. Пример реализации на Python

Вот пример реализации алгоритма топологической сортировки на Python:

```python
from collections import deque

def topological_sort(graph):
    # Счетчик входящих ребер для каждой вершины
    in_degree = {v: 0 for v in graph}
    
    # Подсчет входящих ребер для каждой вершины
    for v in graph:
        for neighbor in graph[v]:
            in_degree[neighbor] += 1
    
    # Очередь для хранения вершин без входящих ребер
    queue = deque()
    
    # Инициализация очереди вершинами без входящих ребер
    for v in graph:
        if in_degree[v] == 0:
            queue.append(v)
    
    # Результат - упорядоченный список вершин
    result = []
    
    # Проход по графу
    while queue:
        # Извлечение вершины из очереди
        v = queue.popleft()
        result.append(v)
        
        # Уменьшение счетчика входящих ребер соседних вершин
        for neighbor in graph[v]:
            in_degree[neighbor] -= 1
            
            # Добавление вершин без входящих ребер в очередь
            if in_degree[neighbor] == 0:
                queue.append(neighbor)
    
    # Проверка на наличие циклов
    if len(result) != len(graph):
        raise ValueError("Граф содержит циклы")
    
    return result
```

Пример использования:

```python
# Пример графа в виде словаря смежности
graph = {
    'A': ['B', 'C'],
    'B': ['D'],
    'C': ['D'],
    'D': ['E'],
    'E': []
}

sorted_nodes = topological_sort(graph)
print(sorted_nodes)  # ['A', 'C', 'B', 'D', 'E']
```

Этот пример реализует алгоритм топологической сортировки с помощью счетчика входящих ребер для каждой вершины и очереди вершин без входящих ребер. Он обрабатывает каждую вершину и ее соседей, уменьшая счетчики входящих ребер и добавляя вершины без входящих ребер в очередь. Результатом является упорядоченный список вершин, представляющих топологический порядок сортировки.

#### 4.3.4. Минимальное остовное дерево

Минимальное остовное дерево (Minimum Spanning Tree, MST) - это подграф связного неориентированного графа, содержащий все вершины исходного графа и минимально возможную сумму весов его ребер. Основная задача MST - найти такое дерево с минимальными затратами.

Принцип работы алгоритма для построения MST основан на жадном подходе. Он начинает с произвольной вершины графа и последовательно добавляет ребра с наименьшими весами, чтобы соединить вершины в дерево. При добавлении ребра проверяется, чтобы оно не образовывало цикл в дереве. Алгоритм продолжается до тех пор, пока не будут соединены все вершины или не останется доступных ребер.

Сложность алгоритма зависит от используемого алгоритма построения MST. Некоторые известные алгоритмы для MST в неориентированных графах имеют следующую сложность:

1. Прима (Prim's algorithm): O(|V|^2) или O(|V| + |E|) при использовании приоритетной очереди.
2. Крускала (Kruskal's algorithm): O(|E| log |E|) или O(|E| log |V|), где |V| - количество вершин, |E| - количество ребер в графе.

Выбор алгоритма зависит от характеристик графа и требований к производительности.

## 5. Алгоритмы генетического поиска

Генетический поиск, или генетический алгоритм, является эволюционным алгоритмом, вдохновленным принципами естественного отбора и генетики. Он используется для решения оптимизационных задач, где требуется нахождение наилучшего решения в большом пространстве возможных вариантов.

Основная идея генетического поиска заключается в создании популяции индивидуальных решений, представленных в виде "генов" или "хромосом". Эти гены представляют параметры или свойства решения, которые могут быть изменены и комбинированы в процессе эволюции.

Принцип работы генетического поиска:
1. Инициализация: Создание начальной популяции случайных индивидуальных решений.
2. Оценка приспособленности: Оценка каждого индивида в популяции на основе функции приспособленности, которая определяет качество решения.
3. Селекция: Выбор лучших индивидов из популяции для следующего поколения на основе их приспособленности. Более приспособленные индивиды имеют больше шансов быть выбранными.
4. Скрещивание: Создание новых индивидов путем комбинирования генов от родителей. Это может включать кроссовер, мутации и другие генетические операторы.
5. Оценка приспособленности новых индивидов.
6. Замещение: Замена старых индивидов новыми в следующем поколении.
7. Повторение шагов 3-6 до достижения условия остановки (например, достижение определенного числа поколений или достижение желаемого уровня приспособленности).
8. Возвращение лучшего решения.

Сложность генетического поиска зависит от размера популяции, количества генов и операций, выполняемых на каждой итерации. В худшем случае, время выполнения может быть экспоненциальным от размера пространства поиска. Однако, правильно настроенный и эффективно реализованный генетический алгоритм может давать хорошие результаты для сложных оптимизационных задач.

### 5.1. Применение

Алгоритмы генетического поиска широко применяются в различных областях для решения оптимизационных задач. Вот некоторые области, в которых генетический поиск находит применение:

1. Оптимизация параметров: Генетический поиск может использоваться для настройки параметров моделей и алгоритмов. Например, в машинном обучении генетический поиск может быть использован для нахождения оптимальных значений параметров моделей, таких как нейронные сети, генетические алгоритмы и другие.

2. Расписание и планирование: Генетический поиск может быть применен для оптимизации расписания, например, для распределения задач между ресурсами или для планирования маршрутов. Это может быть полезно в таких областях, как логистика, транспорт, производство и другие.

3. Проектирование и оптимизация систем: Генетический поиск может использоваться для проектирования и оптимизации сложных систем, таких как электрические схемы, архитектура зданий, сети связи и т. д.

4. Комбинаторная оптимизация: Генетический поиск может решать задачи комбинаторной оптимизации, такие как задачи коммивояжера, задачи о рюкзаке, задачи покрытия множества и другие. В таких задачах требуется нахождение оптимального комбинаторного решения из большого числа возможных вариантов.

5. Искусственная жизнь и эволюционное моделирование: Генетический поиск может быть использован для моделирования эволюции и поведения живых организмов, а также для создания искусственной жизни в компьютерных симуляциях.

6. Распознавание образов: Генетический поиск может использоваться для решения задач распознавания образов, таких как распознавание лиц, распознавание рукописного текста и другие.

7. Проектирование и оптимизация нейронных сетей: Генетический поиск может применяться для оптимизации структуры и весов нейронных сетей, что помогает достичь лучшей производительности и точности моделей.

Это лишь некоторые примеры применения генетического поис

ка, и его возможности не ограничиваются этими областями. Генетический поиск может быть применен практически в любой ситуации, где требуется оптимизация и нахождение наилучшего решения в большом пространстве возможных вариантов.

### 5.2. Примеры

#### 5.2.1. Пример реализации на PHP

Вот пример простой реализации генетического алгоритма на PHP для решения задачи поиска оптимального значения функции:

```php
# Python code

# Генерация случайной популяции
function generatePopulation(populationSize, chromosomeLength) {
    population = []
    for (i = 0 i < populationSize i++) {
        chromosome = ''
        for (j = 0 j < chromosomeLength j++) {
            chromosome .= mt_rand(0, 1)
        }
        population[] = chromosome
    }
    return population
}

# Вычисление значения функции для хромосомы
function fitnessFunction(chromosome) {
    x = bindec(chromosome)
    return x * x # Пример функции: y = x^2
}

# Выбор родителей для скрещивания (турнирный отбор)
function selectParents(population, tournamentSize) {
    parents = []
    populationSize = count(population)
    for (i = 0 i < tournamentSize i++) {
        randomIndex = mt_rand(0, populationSize - 1)
        parents[] = population[randomIndex]
    }
    return parents
}

# Одноточечное скрещивание
function crossover(parent1, parent2) {
    crossoverPoint = mt_rand(1, strlen(parent1) - 1)
    child1 = substr(parent1, 0, crossoverPoint) . substr(parent2, crossoverPoint)
    child2 = substr(parent2, 0, crossoverPoint) . substr(parent1, crossoverPoint)
    return [child1, child2]
}

# Мутация (случайное изменение одного бита)
function mutate(chromosome, mutationRate) {
    mutatedChromosome = ''
    for (i = 0 i < strlen(chromosome) i++) {
        if (mt_rand() / mt_getrandmax() < mutationRate) {
            mutatedChromosome .= (chromosome[i] == '0') ? '1' : '0'
        } else {
            mutatedChromosome .= chromosome[i]
        }
    }
    return mutatedChromosome
}

# Генетический алгоритм
function geneticAlgorithm(populationSize, chromosomeLength, tournamentSize, mutationRate, maxGenerations) {
    # Генерация начальной популяции
    population = generatePopulation(populationSize, chromosomeLength)
    generation = 1

    while (generation <= maxGenerations) {
        # Вычисление приспособленности
        fitnessScores = []
        foreach (population as chromosome) {
            fitnessScores[] = fitnessFunction(chromosome)
        }

        # Проверка наличия решения
        if (in_array(0, fitnessScores)) {
            index = array_search(0, fitnessScores)
            return population[index]
        }

        # Создание новой популяции
        newPopulation = []

        while (count(newPopulation) < populationSize) {
            # Выбор родителей
            parents = selectParents(population, tournamentSize)

            # Скрещивание и мутация
            list(child1, child2) = crossover(parents[0], parents[1])
            child1 = mutate(child1, mutationRate)
            child2 = mutate(child2, mutationRate)

            # Добавление потомков в новую популяцию
            newPopulation[] = child1
            newPopulation[] = child2
        }

        # Замена старой популяции новой
        population = newPopulation
        generation++
    }

    # Если не удалось найти решение, вернуть лучшую найденную хромосому
    bestIndex = array_search(min(fitnessScores), fitnessScores)
    return population[bestIndex]
}

# Пример использования генетического алгоритма
populationSize = 100
chromosomeLength = 8 # Длина хромосомы (количество битов)
tournamentSize = 5 # Размер турнира для выбора родителей
mutationRate = 0.01 # Вероятность мутации
maxGenerations = 100 # Максимальное количество поколений

result = geneticAlgorithm(populationSize, chromosomeLength, tournamentSize, mutationRate, maxGenerations)
print("Решение: " . bindec(result)

?>
```

В этом примере реализуется простой генетический алгоритм для поиска оптимального значения функции y = x^2. Популяция состоит из бинарных хромосом переменной длины, алгоритм включает операции выбора родителей, скрещивания, мутации и формирования новой популяции.

#### 5.2.2. Пример реализации на Python

Вот пример реализации простого генетического алгоритма на Python:

```python
import random

# Генерация начальной популяции
def generate_population(size, chromosome_length):
    population = []
    for _ in range(size):
        chromosome = [random.randint(0, 1) for _ in range(chromosome_length)]
        population.append(chromosome)
    return population

# Оценка приспособленности
def fitness(chromosome):
    # Здесь вычисляется и возвращается значение приспособленности для данного хромосомы
    # Чем лучше хромосома соответствует поставленной задаче, тем выше значение приспособленности
    return sum(chromosome)

# Оператор выбора
def selection(population):
    # Здесь выбираются лучшие хромосомы из популяции
    # Возвращается новая популяция из выбранных хромосом
    sorted_population = sorted(population, key=lambda chromosome: fitness(chromosome), reverse=True)
    return sorted_population[:len(population)#2]

# Оператор скрещивания
def crossover(parent1, parent2):
    # Здесь выполняется скрещивание двух родителей и создается новая хромосома-потомок
    # Возвращается потомок
    crossover_point = random.randint(1, len(parent1) - 1)
    child = parent1[:crossover_point] + parent2[crossover_point:]
    return child

# Оператор мутации
def mutate(chromosome, mutation_rate):
    # Здесь выполняется мутация хромосомы с заданной вероятностью
    # Возвращается мутированная хромосома
    for i in range(len(chromosome)):
        if random.random() < mutation_rate:
            chromosome[i] = 1 - chromosome[i]
    return chromosome

# Генетический алгоритм
def genetic_algorithm(population_size, chromosome_length, generations, mutation_rate):
    population = generate_population(population_size, chromosome_length)

    for _ in range(generations):
        new_population = []

        for _ in range(population_size # 2):
            parent1 = random.choice(population)
            parent2 = random.choice(population)

            child = crossover(parent1, parent2)
            child = mutate(child, mutation_rate)

            new_population.append(child)

        population = selection(population) + new_population

    best_chromosome = max(population, key=lambda chromosome: fitness(chromosome))
    return best_chromosome

# Пример использования
population_size = 100
chromosome_length = 10
generations = 100
mutation_rate = 0.1

best_chromosome = genetic_algorithm(population_size, chromosome_length, generations, mutation_rate)
print("Best chromosome:", best_chromosome)
```

Обратите внимание, что это всего лишь пример простого генетического алгоритма, и его можно дальше настраивать и модифицировать в зависимости от конкретной задачи и требований.

## 6. Динамическое программирование

Динамическое программирование (Dynamic Programming, DP) - это метод решения задач, основанный на разбиении сложной задачи на более простые подзадачи и последующем комбинировании их решений для получения оптимального решения всей задачи. Этот подход основан на принципе оптимальной подструктуры, то есть оптимальное решение задачи может быть получено из оптимальных решений ее подзадач.

Основные принципы динамического программирования:

1. Мемоизация: Для избежания повторных вычислений сохраняются результаты уже решенных подзадач. Таким образом, при повторном вызове функции или решении подзадачи результат берется из кэша, что позволяет значительно ускорить процесс.

2. Разбиение на подзадачи: Сложную задачу разбивают на более маленькие подзадачи, которые могут быть решены отдельно. Затем результаты этих подзадач комбинируются для получения оптимального решения всей задачи.

3. Определение зависимостей: Важным аспектом динамического программирования является определение зависимостей между подзадачами. Это помогает определить порядок решения подзадач и правильно комбинировать их решения.

4. Оптимальная структура: Динамическое программирование основано на предположении, что оптимальное решение задачи можно получить из оптимальных решений ее подзадач. Это позволяет использовать результаты предыдущих подзадач для получения оптимального решения текущей подзадачи.

Динамическое программирование часто применяется для решения задач оптимизации, где требуется найти наилучшее решение среди множества возможных вариантов. Оно широко используется в различных областях, таких как алгоритмы на графах, численные методы, оптимизация расписаний, робототехника и другие.

## 7. Жадные алгоритмы

Жадные алгоритмы (greedy algorithms) - это класс алгоритмов, которые стремятся сделать локально оптимальный выбор на каждом шаге с надеждой, что такие выборы приведут к глобально оптимальному решению задачи. 

Принципы жадных алгоритмов:

1. Локальная оптимальность: На каждом шаге алгоритма делается выбор, который наилучшим образом решает подзадачу. Это означает, что алгоритм выбирает оптимальное решение для текущего шага, не принимая во внимание будущие шаги или глобальное оптимальное решение задачи.

2. Нет отката: Жадные алгоритмы обычно принимают решения без возможности отмены или изменения. Решение, принятое на одном шаге, не пересматривается на следующих шагах.

3. Определение критерия оптимальности: Жадные алгоритмы основаны на определении критерия оптимальности для задачи. Этот критерий позволяет выбирать наиболее подходящий вариант на каждом шаге.

4. Комбинирование локальных оптимальных решений: Жадные алгоритмы комбинируют локально оптимальные решения, надеясь, что они приведут к глобально оптимальному решению всей задачи.

Важно отметить, что хотя жадные алгоритмы могут быть простыми и эффективными, они не всегда гарантируют нахождение глобально оптимального решения для всех задач. Однако во многих случаях они дают достаточно хорошие результаты или приближенные решения, которые близки к оптимальным. Поэтому при использовании жадных алгоритмов важно внимательно определить критерий оптимальности и проверить их корректность и эффективность для конкретной задачи.

## 8. Рекурсия

Рекурсия - это процесс, при котором функция вызывает саму себя для решения задачи. Она является важным понятием в программировании и может быть использована для элегантного решения многих задач.

Принципы работы с рекурсией:

1. Базовый случай: Рекурсивная функция должна содержать базовый случай, при котором происходит прекращение рекурсии. Базовый случай обычно определяет простую задачу, которую можно решить напрямую без дальнейшего вызова функции.

2. Рекурсивный случай: Рекурсивная функция вызывает саму себя с некоторыми изменениями входных данных. Это позволяет разбить сложную задачу на более простые подзадачи. Каждый рекурсивный вызов должен быть сделан с надеждой на то, что он приблизит к достижению базового случая.

3. Прогресс: Каждый рекурсивный вызов должен двигаться в сторону базового случая. Если вызовы не продвигаются к базовому случаю, то может возникнуть бесконечная рекурсия.

4. Стек вызовов: При вызове рекурсивной функции каждый вызов помещается в стек вызовов, чтобы сохранить контекст выполнения. Когда базовый случай достигнут, функция начинает возвращаться к предыдущим вызовам из стека, завершая выполнение задачи.

Рекурсия может быть мощным инструментом, но требует осторожного применения. Неправильное использование рекурсии может привести к переполнению стека вызовов (stack overflow) или долгому времени выполнения. Поэтому важно выбирать подходящие базовые случаи и убеждаться в прогрессе к ним при каждом рекурсивном вызове.

